{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from operator import itemgetter\n",
    "\n",
    "#importing base learners of Voting Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Importing three component ensembles\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#importing SVC for second-step classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining ml techniques\n",
    "base_learner1 = LogisticRegression(random_state=1)\n",
    "base_learner2 = DecisionTreeClassifier()\n",
    "base_learner3 = GaussianNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicts bug and their probabilities for given datafile and classifier pair\n",
    "\n",
    "def predict_util(datafile, classifiertype):\n",
    "    ncols = datafile.columns\n",
    "    #extracting relevant columns, software metrics in X, and labels in Y\n",
    "    \n",
    "    ncols = ncols[ :-1]\n",
    "    X     = datafile.iloc[ : , :-1]\n",
    "    X1    = datafile.as_matrix(ncols)\n",
    "    y = datafile['buggy']\n",
    "    Y = np.array(y)\n",
    "    \n",
    "    #performing leave-one out validation for instances less than 100\n",
    "    #and 10 fold validation for others\n",
    "    npoints = X.shape[0]\n",
    "   \n",
    "    if npoints <= 100:\n",
    "        kf = KFold(n_splits = npoints)\n",
    "    else:\n",
    "        kf = KFold(n_splits = 10)\n",
    "        \n",
    "    kf.get_n_splits(X)\n",
    "    train_X = []\n",
    "    train_Y  = []\n",
    "    prediction   = []\n",
    "    predict_prob = [] \n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if classifiertype == 'Voting':\n",
    "            classifier = VotingClassifier(estimators=[\n",
    "                                         ('logregression', base_learner1), \n",
    "                                         ('dtree', base_learner2), \n",
    "                                         ('gnb', base_learner3)], \n",
    "                                          voting='soft')      \n",
    "        elif classifiertype == 'RandomForest':\n",
    "            classifier = RandomForestClassifier()\n",
    "        else:\n",
    "            classifier = AdaBoostClassifier(base_estimator = RandomForestClassifier(), n_estimators = 100, learning_rate = 0.5)\n",
    "            \n",
    "        for i in train_index:\n",
    "                train_X.append(X1[i])\n",
    "                train_Y.append(Y[i])\n",
    "        \n",
    "        classifier.fit(train_X, train_Y)\n",
    "        \n",
    "        for j in test_index:\n",
    "            prediction.append(classifier.predict([X1[j]])[0])\n",
    "            predict_prob.append(classifier.predict_proba([X1[j]])[0][1])\n",
    "        \n",
    "        train_X  = []\n",
    "        train_Y  = []\n",
    "    \n",
    "    return prediction, Y, predict_prob\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computePerformanceMeasures(predictions, labels, prediction_probability):\n",
    "    \n",
    "    precision = precision_score(y_true = labels, y_pred = predictions)\n",
    "    recall    = recall_score(y_true = labels, y_pred = predictions)\n",
    "    roc_score = roc_auc_score(labels, prediction_probability)\n",
    "    accuracy  = accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    f_measure = 2*(precision * recall)/float(precision + recall) \n",
    "    g_mean = math.sqrt(precision * recall)\n",
    "    \n",
    "    metrics = [precision, recall, roc_score, accuracy, f_measure, g_mean]\n",
    "    \n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    directory = 'dataset/dataset/'\n",
    "    \n",
    "    for projectName in os.listdir(directory):\n",
    "        performanceMetrics = []\n",
    "    \n",
    "        inputData = pd.read_csv(directory + projectName, dtype={'buggy':np.bool})\n",
    "        projectData = pd.read_csv(directory + projectName, dtype={'buggy':np.bool})\n",
    "        \n",
    "        metricsFrame = pd.DataFrame(performanceMetrics, \n",
    "                                    index = ['Precision', 'Recall', 'Auc_Score', 'Accuracy', 'F_Measure', 'GMean'])\n",
    "        \n",
    "        predictionEnsemble1, YEnsemble1, predict_probEnsemble1 = predict_util(inputData, 'Voting')\n",
    "        projectData['Voting_Prediction'] = predictionEnsemble1\n",
    "        projectData['Voting_Pred_Prob']  = predict_probEnsemble1\n",
    "        VotingMetrics = computePerformanceMeasures(predictionEnsemble1, YEnsemble1, predict_probEnsemble1)\n",
    "        metricsFrame.insert(loc = 0, column = 'Voting', value = VotingMetrics)\n",
    "                \n",
    "            \n",
    "        predictionEnsemble2, YEnsemble2, predict_probEnsemble2 = predict_util(inputData, 'RandomForest')\n",
    "        projectData['RandomForest_Prediction'] = predictionEnsemble2\n",
    "        projectData['RandomForest_Pred_Prob']  = predict_probEnsemble2\n",
    "        RandomForestMetrics = computePerformanceMeasures(predictionEnsemble2, YEnsemble2, predict_probEnsemble2)\n",
    "        metricsFrame.insert(loc = 1, column='RandomForest', value = RandomForestMetrics)\n",
    "        \n",
    "        predictionEnsemble3, YEnsemble3, predict_probEnsemble3 = predict_util(inputData, 'AdaBoost')\n",
    "        projectData['AdaBoost_Prediction'] = predictionEnsemble3\n",
    "        projectData['AdaBoost_Pred_Prob']  = predict_probEnsemble3\n",
    "        AdaBoostMetrics = computePerformanceMeasures(predictionEnsemble3, YEnsemble3, predict_probEnsemble3)\n",
    "        metricsFrame.insert(loc = 2, column='AdaBoost', value = AdaBoostMetrics)\n",
    "        \n",
    "        metricsFrame.to_csv('dataset/metrics/' + projectName)\n",
    "        print(projectName)\n",
    "        print(metricsFrame)\n",
    "        \n",
    "        projectData.to_csv('dataset/annotated/' + projectName, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synapse-1.2.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.666667      0.600000  0.450000\n",
      "Recall     0.347826      0.391304  0.391304\n",
      "Auc_Score  0.783421      0.674319  0.761276\n",
      "Accuracy   0.853846      0.846154  0.807692\n",
      "F_Measure  0.457143      0.473684  0.418605\n",
      "GMean      0.481543      0.484544  0.419627\n",
      "zuzel.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.875000      0.777778  0.777778\n",
      "Recall     0.777778      0.777778  0.777778\n",
      "Auc_Score  0.888889      0.916667  0.902778\n",
      "Accuracy   0.823529      0.764706  0.764706\n",
      "F_Measure  0.823529      0.777778  0.777778\n",
      "GMean      0.824958      0.777778  0.777778\n",
      "ivy-2.0.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.770270      0.769231  0.791045\n",
      "Recall     0.686747      0.602410  0.638554\n",
      "Auc_Score  0.875502      0.901720  0.904604\n",
      "Accuracy   0.854730      0.837838  0.851351\n",
      "F_Measure  0.726115      0.675676  0.706667\n",
      "GMean      0.727311      0.680729  0.710721\n",
      "jedit-4.3.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.760331      0.919463  0.921569\n",
      "Recall     0.630137      0.938356  0.965753\n",
      "Auc_Score  0.895205      0.970228  0.967565\n",
      "Accuracy   0.817982      0.953947  0.962719\n",
      "F_Measure  0.689139      0.928814  0.943144\n",
      "GMean      0.692179      0.928862  0.943402\n",
      "kalkulator.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.615385      0.777778  0.727273\n",
      "Recall     0.800000      0.700000  0.800000\n",
      "Auc_Score  0.885714      0.828571  0.800000\n",
      "Accuracy   0.708333      0.791667  0.791667\n",
      "F_Measure  0.695652      0.736842  0.761905\n",
      "GMean      0.701646      0.737865  0.762770\n",
      "velocity-1.6.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.647059      0.592593  0.694444\n",
      "Recall     0.511628      0.372093  0.581395\n",
      "Auc_Score  0.826404      0.730327  0.812309\n",
      "Accuracy   0.767606      0.732394  0.795775\n",
      "F_Measure  0.571429      0.457143  0.632911\n",
      "GMean      0.575372      0.469574  0.635411\n",
      "redaktor.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.897959      0.933333  0.913043\n",
      "Recall     0.862745      0.823529  0.823529\n",
      "Auc_Score  0.924683      0.931257  0.930681\n",
      "Accuracy   0.911765      0.911765  0.904412\n",
      "F_Measure  0.880000      0.875000  0.865979\n",
      "GMean      0.880176      0.876714  0.867132\n",
      "tomcat.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.727273      0.857143  0.897727\n",
      "Recall     0.448598      0.560748  0.738318\n",
      "Auc_Score  0.856014      0.920668  0.930317\n",
      "Accuracy   0.877971      0.909667  0.941363\n",
      "F_Measure  0.554913      0.677966  0.810256\n",
      "GMean      0.571186      0.693283  0.814130\n",
      "xerces-1.4.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.927536      0.902778  0.907143\n",
      "Recall     0.927536      0.942029  0.920290\n",
      "Auc_Score  0.914068      0.922705  0.905578\n",
      "Accuracy   0.915612      0.907173  0.898734\n",
      "F_Measure  0.927536      0.921986  0.913669\n",
      "GMean      0.927536      0.922195  0.913693\n",
      "szybkafucha.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.750000      0.727273  0.727273\n",
      "Recall     0.900000      0.800000  0.800000\n",
      "Auc_Score  0.762500      0.806250  0.818750\n",
      "Accuracy   0.777778      0.722222  0.722222\n",
      "F_Measure  0.818182      0.761905  0.761905\n",
      "GMean      0.821584      0.762770  0.762770\n",
      "termoproject.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.600000      0.400000  0.400000\n",
      "Recall     0.375000      0.250000  0.250000\n",
      "Auc_Score  0.846591      0.761364  0.764205\n",
      "Accuracy   0.766667      0.700000  0.700000\n",
      "F_Measure  0.461538      0.307692  0.307692\n",
      "GMean      0.474342      0.316228  0.316228\n",
      "wspomaganiepi.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.888889      0.875000  0.875000\n",
      "Recall     0.888889      0.777778  0.777778\n",
      "Auc_Score  0.861111      0.916667  0.944444\n",
      "Accuracy   0.846154      0.769231  0.769231\n",
      "F_Measure  0.888889      0.823529  0.823529\n",
      "GMean      0.888889      0.824958  0.824958\n",
      "sklebagd.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.857143      0.833333  0.833333\n",
      "Recall     0.857143      0.714286  0.714286\n",
      "Auc_Score  0.809524      0.714286  0.761905\n",
      "Accuracy   0.800000      0.700000  0.700000\n",
      "F_Measure  0.857143      0.769231  0.769231\n",
      "GMean      0.857143      0.771517  0.771517\n",
      "camel-1.6.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.629630      0.745614  0.708029\n",
      "Recall     0.274194      0.456989  0.521505\n",
      "Auc_Score  0.746755      0.780127  0.780633\n",
      "Accuracy   0.771468      0.819945  0.821330\n",
      "F_Measure  0.382022      0.566667  0.600619\n",
      "GMean      0.415500      0.583727  0.607652\n",
      "log4j-1.2.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.911504      0.927273  0.926230\n",
      "Recall     0.865546      0.857143  0.949580\n",
      "Auc_Score  0.939694      0.946762  0.975334\n",
      "Accuracy   0.872549      0.877451  0.926471\n",
      "F_Measure  0.887931      0.890830  0.937759\n",
      "GMean      0.888228      0.891518  0.937832\n",
      "intercafe.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.700000      0.833333  0.727273\n",
      "Recall     0.777778      0.555556  0.888889\n",
      "Auc_Score  0.746032      0.928571  0.908730\n",
      "Accuracy   0.782609      0.782609  0.826087\n",
      "F_Measure  0.736842      0.666667  0.800000\n",
      "GMean      0.737865      0.680414  0.804030\n",
      "systemdata.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.600000      0.500000  0.428571\n",
      "Recall     0.428571      0.428571  0.428571\n",
      "Auc_Score  0.835498      0.746753  0.653680\n",
      "Accuracy   0.850000      0.825000  0.800000\n",
      "F_Measure  0.500000      0.461538  0.428571\n",
      "GMean      0.507093      0.462910  0.428571\n",
      "xalan-2.7.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.962585      0.985965  0.986111\n",
      "Recall     0.986063      0.979094  0.989547\n",
      "Auc_Score  0.998055      0.997649  0.997837\n",
      "Accuracy   0.975884      0.983923  0.988746\n",
      "F_Measure  0.974182      0.982517  0.987826\n",
      "GMean      0.974253      0.982523  0.987828\n",
      "e-learning.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.800000      0.800000  0.780000\n",
      "Recall     0.653061      0.734694  0.795918\n",
      "Auc_Score  0.875333      0.923913  0.922915\n",
      "Accuracy   0.822695      0.843972  0.851064\n",
      "F_Measure  0.719101      0.765957  0.787879\n",
      "GMean      0.722806      0.766652  0.787919\n",
      "workflow.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.777778      0.700000  0.700000\n",
      "Recall     0.777778      0.777778  0.777778\n",
      "Auc_Score  0.675214      0.658120  0.623932\n",
      "Accuracy   0.818182      0.772727  0.772727\n",
      "F_Measure  0.777778      0.736842  0.736842\n",
      "GMean      0.777778      0.737865  0.737865\n",
      "prop-6.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.544304      0.658683  0.678571\n",
      "Recall     0.502924      0.643275  0.777778\n",
      "Auc_Score  0.817173      0.858030  0.898810\n",
      "Accuracy   0.746365      0.809370  0.836834\n",
      "F_Measure  0.522796      0.650888  0.724796\n",
      "GMean      0.523205      0.650933  0.726483\n",
      "serapion.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.571429      0.571429  0.571429\n",
      "Recall     0.571429      0.571429  0.571429\n",
      "Auc_Score  0.777143      0.820000  0.822857\n",
      "Accuracy   0.812500      0.812500  0.812500\n",
      "F_Measure  0.571429      0.571429  0.571429\n",
      "GMean      0.571429      0.571429  0.571429\n",
      "lucene-2.4.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.666667      0.642857  0.656863\n",
      "Recall     0.641509      0.594340  0.632075\n",
      "Auc_Score  0.703815      0.663643  0.686917\n",
      "Accuracy   0.634518      0.604061  0.624365\n",
      "F_Measure  0.653846      0.617647  0.644231\n",
      "GMean      0.653967      0.618123  0.644350\n",
      "poi-2.5.csv\n",
      "             Voting  RandomForest  AdaBoost\n",
      "Precision  0.909639      0.903614  0.881356\n",
      "Recall     0.857955      0.852273  0.886364\n",
      "Auc_Score  0.902379      0.906406  0.924357\n",
      "Accuracy   0.850187      0.842697  0.846442\n",
      "F_Measure  0.883041      0.877193  0.883853\n",
      "GMean      0.883419      0.877568  0.883856\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bestEnsembleSelector():\n",
    "    annotated_directory   = 'dataset/annotated/'\n",
    "    performance_directory = 'dataset/metrics/'\n",
    "\n",
    "    for projectName in os.listdir(annotated_directory):\n",
    "        print(projectName)\n",
    "        annotatedData = pd.read_csv(annotated_directory + projectName, dtype={'buggy':np.bool})\n",
    "        metricData    = pd.read_csv(performance_directory + projectName)\n",
    "\n",
    "\n",
    "        predictionMatrix = annotatedData.as_matrix(columns = ['buggy','Voting_Prediction','AdaBoost_Prediction','RandomForest_Prediction'])\n",
    "        print(metricData)\n",
    "        \n",
    "       # defining constants\n",
    "        auc_score_constant    = 2     # auc_score is at the 2nd row\n",
    "        voting_constant       = 'Voting'\n",
    "        adaBoost_constant     = 'AdaBoost'\n",
    "        randomForest_constant = 'RandomForest'\n",
    "        \n",
    "        ensemble=[]\n",
    "        \n",
    "        for i in range(len(predictionMatrix)):\n",
    "            if   predictionMatrix[i][0] == predictionMatrix[i][1] and predictionMatrix[i][0] != predictionMatrix[i][2] and predictionMatrix[i][0] != predictionMatrix[i][3]:\n",
    "                ensemble.append('Voting')\n",
    "            elif predictionMatrix[i][0] == predictionMatrix[i][2] and predictionMatrix[i][0] != predictionMatrix[i][1] and predictionMatrix[i][0] != predictionMatrix[i][3]:\n",
    "                ensemble.append('AdaBoost')\n",
    "            elif predictionMatrix[i][0] == predictionMatrix[i][3] and predictionMatrix[i][0] != predictionMatrix[i][1] and predictionMatrix[i][0] != predictionMatrix[i][2]:\n",
    "                ensemble.append('RandomForest')\n",
    "            else:\n",
    "                p_voting       = metricData.loc[auc_score_constant, voting_constant]\n",
    "                p_adaBoost     = metricData.loc[auc_score_constant, adaBoost_constant]\n",
    "                p_randomForest = metricData.loc[auc_score_constant, randomForest_constant]\n",
    "\n",
    "                if p_voting > p_adaBoost and p_voting > p_randomForest:\n",
    "                    ensemble.append('Voting')\n",
    "\n",
    "                elif p_adaBoost>p_randomForest and p_adaBoost > p_voting:\n",
    "                    ensemble.append('AdaBoost')\n",
    "\n",
    "                else:\n",
    "                    ensemble.append('RandomForest')\n",
    "                \n",
    "        annotatedData['selectedEnsemble'] = ensemble\n",
    "        annotatedData.to_csv(annotated_directory + projectName, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.635294      0.767857  0.700000\n",
      "1     Recall  0.290323      0.462366  0.526882\n",
      "2  Auc_Score  0.748099      0.771009  0.778306\n",
      "3   Accuracy  0.774238      0.825485  0.819945\n",
      "4  F_Measure  0.398524      0.577181  0.601227\n",
      "5      GMean  0.429465      0.595845  0.607303\n",
      "e-learning.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.783784      0.791667  0.854167\n",
      "1     Recall  0.591837      0.775510  0.836735\n",
      "2  Auc_Score  0.869343      0.923580  0.928350\n",
      "3   Accuracy  0.801418      0.851064  0.893617\n",
      "4  F_Measure  0.674419      0.783505  0.845361\n",
      "5      GMean  0.681082      0.783547  0.845406\n",
      "intercafe.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.700000      0.777778  0.714286\n",
      "1     Recall  0.777778      0.777778  0.555556\n",
      "2  Auc_Score  0.746032      0.892857  0.928571\n",
      "3   Accuracy  0.782609      0.826087  0.739130\n",
      "4  F_Measure  0.736842      0.777778  0.625000\n",
      "5      GMean  0.737865      0.777778  0.629941\n",
      "ivy-2.0.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.763158      0.861111  0.835821\n",
      "1     Recall  0.698795      0.746988  0.674699\n",
      "2  Auc_Score  0.883704      0.929097  0.912636\n",
      "3   Accuracy  0.854730      0.895270  0.871622\n",
      "4  F_Measure  0.729560      0.800000  0.746667\n",
      "5      GMean  0.730268      0.802022  0.750951\n",
      "jedit-4.3.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.754098      0.924658  0.915033\n",
      "1     Recall  0.630137      0.924658  0.958904\n",
      "2  Auc_Score  0.891471      0.970449  0.965731\n",
      "3   Accuracy  0.815789      0.951754  0.958333\n",
      "4  F_Measure  0.686567      0.924658  0.936455\n",
      "5      GMean  0.689337      0.924658  0.936712\n",
      "kalkulator.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.615385      0.666667  0.700000\n",
      "1     Recall  0.800000      0.800000  0.700000\n",
      "2  Auc_Score  0.885714      0.853571  0.771429\n",
      "3   Accuracy  0.708333      0.750000  0.750000\n",
      "4  F_Measure  0.695652      0.727273  0.700000\n",
      "5      GMean  0.701646      0.730297  0.700000\n",
      "log4j-1.2.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.904348      0.957265  0.963964\n",
      "1     Recall  0.873950      0.941176  0.899160\n",
      "2  Auc_Score  0.936728      0.983589  0.970044\n",
      "3   Accuracy  0.872549      0.941176  0.921569\n",
      "4  F_Measure  0.888889      0.949153  0.930435\n",
      "5      GMean  0.889019      0.949187  0.930998\n",
      "lucene-2.4.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.657143      0.644860  0.633028\n",
      "1     Recall  0.650943      0.650943  0.650943\n",
      "2  Auc_Score  0.695314      0.654520  0.678520\n",
      "3   Accuracy  0.629442      0.619289  0.609137\n",
      "4  F_Measure  0.654028      0.647887  0.641860\n",
      "5      GMean  0.654036      0.647894  0.641923\n",
      "poi-2.5.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.910180      0.911950  0.882022\n",
      "1     Recall  0.863636      0.823864  0.892045\n",
      "2  Auc_Score  0.898008      0.889798  0.911932\n",
      "3   Accuracy  0.853933      0.831461  0.850187\n",
      "4  F_Measure  0.886297      0.865672  0.887006\n",
      "5      GMean  0.886603      0.866788  0.887020\n",
      "prop-6.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.564935      0.690909  0.688172\n",
      "1     Recall  0.508772      0.666667  0.748538\n",
      "2  Auc_Score  0.823426      0.873773  0.901968\n",
      "3   Accuracy  0.756058      0.825525  0.836834\n",
      "4  F_Measure  0.535385      0.678571  0.717087\n",
      "5      GMean  0.536119      0.678680  0.717721\n",
      "redaktor.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.897959      0.902439  0.913043\n",
      "1     Recall  0.862745      0.725490  0.823529\n",
      "2  Auc_Score  0.928143      0.928950  0.925260\n",
      "3   Accuracy  0.911765      0.867647  0.904412\n",
      "4  F_Measure  0.880000      0.804348  0.865979\n",
      "5      GMean  0.880176      0.809142  0.867132\n",
      "serapion.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.571429      0.571429  0.571429\n",
      "1     Recall  0.571429      0.571429  0.571429\n",
      "2  Auc_Score  0.777143      0.825714  0.825714\n",
      "3   Accuracy  0.812500      0.812500  0.812500\n",
      "4  F_Measure  0.571429      0.571429  0.571429\n",
      "5      GMean  0.571429      0.571429  0.571429\n",
      "sklebagd.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.857143      0.833333  0.833333\n",
      "1     Recall  0.857143      0.714286  0.714286\n",
      "2  Auc_Score  0.809524      0.714286  0.714286\n",
      "3   Accuracy  0.800000      0.700000  0.700000\n",
      "4  F_Measure  0.857143      0.769231  0.769231\n",
      "5      GMean  0.857143      0.771517  0.771517\n",
      "synapse-1.2.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.615385      0.578947  0.555556\n",
      "1     Recall  0.347826      0.478261  0.434783\n",
      "2  Auc_Score  0.769606      0.727347  0.748070\n",
      "3   Accuracy  0.846154      0.846154  0.838462\n",
      "4  F_Measure  0.444444      0.523810  0.487805\n",
      "5      GMean  0.462652      0.526201  0.491473\n",
      "systemdata.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.600000      0.500000  0.600000\n",
      "1     Recall  0.428571      0.428571  0.428571\n",
      "2  Auc_Score  0.835498      0.818182  0.670996\n",
      "3   Accuracy  0.850000      0.825000  0.850000\n",
      "4  F_Measure  0.500000      0.461538  0.500000\n",
      "5      GMean  0.507093      0.462910  0.507093\n",
      "szybkafucha.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.750000      0.750000  0.692308\n",
      "1     Recall  0.900000      0.900000  0.900000\n",
      "2  Auc_Score  0.762500      0.843750  0.831250\n",
      "3   Accuracy  0.777778      0.777778  0.722222\n",
      "4  F_Measure  0.818182      0.818182  0.782609\n",
      "5      GMean  0.821584      0.821584  0.789352\n",
      "termoproject.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.500000      0.333333  0.400000\n",
      "1     Recall  0.375000      0.125000  0.250000\n",
      "2  Auc_Score  0.840909      0.750000  0.784091\n",
      "3   Accuracy  0.733333      0.700000  0.700000\n",
      "4  F_Measure  0.428571      0.181818  0.307692\n",
      "5      GMean  0.433013      0.204124  0.316228\n",
      "tomcat.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.705882      0.885714  0.857143\n",
      "1     Recall  0.448598      0.579439  0.672897\n",
      "2  Auc_Score  0.855764      0.915201  0.933848\n",
      "3   Accuracy  0.874802      0.916006  0.925515\n",
      "4  F_Measure  0.548571      0.700565  0.753927\n",
      "5      GMean  0.562723      0.716392  0.759453\n",
      "velocity-1.6.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.645161      0.615385  0.645161\n",
      "1     Recall  0.465116      0.372093  0.465116\n",
      "2  Auc_Score  0.835565      0.768381  0.781184\n",
      "3   Accuracy  0.760563      0.739437  0.760563\n",
      "4  F_Measure  0.540541      0.463768  0.540541\n",
      "5      GMean  0.547791      0.478519  0.547791\n",
      "workflow.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.777778      0.700000  0.700000\n",
      "1     Recall  0.777778      0.777778  0.777778\n",
      "2  Auc_Score  0.675214      0.709402  0.615385\n",
      "3   Accuracy  0.818182      0.772727  0.772727\n",
      "4  F_Measure  0.777778      0.736842  0.736842\n",
      "5      GMean  0.777778      0.737865  0.737865\n",
      "wspomaganiepi.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.888889      0.875000  1.000000\n",
      "1     Recall  0.888889      0.777778  0.777778\n",
      "2  Auc_Score  0.861111      0.875000  0.916667\n",
      "3   Accuracy  0.846154      0.769231  0.846154\n",
      "4  F_Measure  0.888889      0.823529  0.875000\n",
      "5      GMean  0.888889      0.824958  0.881917\n",
      "xalan-2.7.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.965870      0.989399  0.989510\n",
      "1     Recall  0.986063      0.975610  0.986063\n",
      "2  Auc_Score  0.998211      0.996074  0.997457\n",
      "3   Accuracy  0.977492      0.983923  0.988746\n",
      "4  F_Measure  0.975862      0.982456  0.987784\n",
      "5      GMean  0.975914      0.982480  0.987785\n",
      "xerces-1.4.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.927536      0.920290  0.900709\n",
      "1     Recall  0.927536      0.920290  0.920290\n",
      "2  Auc_Score  0.914068      0.921644  0.907847\n",
      "3   Accuracy  0.915612      0.907173  0.894515\n",
      "4  F_Measure  0.927536      0.920290  0.910394\n",
      "5      GMean  0.927536      0.920290  0.910447\n",
      "zuzel.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.875000      0.750000  0.750000\n",
      "1     Recall  0.777778      0.666667  0.666667\n",
      "2  Auc_Score  0.916667      0.909722  0.895833\n",
      "3   Accuracy  0.823529      0.705882  0.705882\n",
      "4  F_Measure  0.823529      0.705882  0.705882\n",
      "5      GMean  0.824958      0.707107  0.707107\n"
     ]
    }
   ],
   "source": [
    "bestEnsembleSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svctrain():\n",
    "    directory = 'dataset/dataset/'\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    DSE_directory = 'dataset/DSE/'\n",
    "    for projectName in os.listdir(directory):\n",
    "        print(projectName)\n",
    "        projectData = pd.read_csv(directory + projectName)\n",
    "        annotatedData = pd.read_csv(annotated_directory + projectName)\n",
    "        \n",
    "        #X contains software metrics and Y best ensemble selected\n",
    "        X = np.array(projectData.iloc[ : , :-1])\n",
    "        Y = np.array(annotatedData.iloc[ : , -1])\n",
    "        \n",
    "        npoints = X.shape[0]\n",
    "        \n",
    "        if npoints <= 100:\n",
    "            kf = KFold(n_splits = npoints)\n",
    "        else:\n",
    "            kf = KFold(n_splits = 10)\n",
    "        \n",
    "        kf.get_n_splits(X)\n",
    "        train_X = []\n",
    "        train_Y = []\n",
    "        \n",
    "        predictedEnsemble = []\n",
    "        predict_prob      = []\n",
    "        final_prediction  = []  # this stores the prediction(bugginess) of the best ensemble predicted by SVC\n",
    "        \n",
    "        prediction_constant = '_Prediction'\n",
    "        probab_constant = '_Pred_Prob'\n",
    "        \n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            classifier = SVC(probability = True)\n",
    "            \n",
    "            for i in train_index:\n",
    "                train_X.append(X[i])\n",
    "                train_Y.append(Y[i])\n",
    "            \n",
    "            unique_labels = np.unique(train_Y)\n",
    "            if unique_labels.size == 1:\n",
    "                for j in test_index:\n",
    "                    predictedEnsemble.append(unique_labels[0])\n",
    "                    predict_prob.append(annotatedData.loc[j, unique_labels[0] + probab_constant])\n",
    "                    final_prediction.append(annotatedData.loc[j, unique_labels[0] + prediction_constant])\n",
    "           \n",
    "            else:\n",
    "                classifier.fit(train_X, train_Y)\n",
    "                \n",
    "                for j in test_index:\n",
    "                    predictedBestEnsemble = classifier.predict([X[j]])[0]\n",
    "                    predictedEnsemble.append(predictedBestEnsemble)\n",
    "                    final_prediction.append(annotatedData.loc[j, predictedBestEnsemble + prediction_constant])\n",
    "                    \n",
    "            # total probability of available classifiers, i.e the classifiers reported in unique_labels predicting true\n",
    "                    predict_proba_true = 0\n",
    "                    \n",
    "            # probability of classifiers being predicted\n",
    "                    predict_proba_classifiers = classifier.predict_proba([X[j]])[0]\n",
    "                    k = 0\n",
    "            # class probabilities are always reported in a sorted by name fashion, i.e AdaBoost, RandomForest, Voting \n",
    "            # np.unique also reports labels in a sorted by name fashion\n",
    "                    for classifierName in unique_labels:\n",
    "                        predict_proba_true +=  predict_proba_classifiers[k] * annotatedData.loc[j, classifierName + probab_constant]\n",
    "                        k += 1\n",
    "                    predict_prob.append(predict_proba_true)\n",
    "                    \n",
    "        annotatedData['PredictedEnsemble'] = predictedEnsemble\n",
    "        annotatedData['DSE_Prediction'] = final_prediction\n",
    "        annotatedData['DSE_Pred_Prob'] = predict_prob\n",
    "        annotatedData.to_csv(DSE_directory + projectName, index = False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n",
      "e-learning.csv\n",
      "intercafe.csv\n",
      "ivy-2.0.csv\n",
      "jedit-4.3.csv\n",
      "kalkulator.csv\n",
      "log4j-1.2.csv\n",
      "lucene-2.4.csv\n",
      "poi-2.5.csv\n",
      "prop-6.csv\n",
      "redaktor.csv\n",
      "serapion.csv\n",
      "sklebagd.csv\n",
      "synapse-1.2.csv\n",
      "systemdata.csv\n",
      "szybkafucha.csv\n",
      "termoproject.csv\n",
      "tomcat.csv\n",
      "velocity-1.6.csv\n",
      "workflow.csv\n",
      "wspomaganiepi.csv\n",
      "xalan-2.7.csv\n",
      "xerces-1.4.csv\n",
      "zuzel.csv\n"
     ]
    }
   ],
   "source": [
    "svctrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computePerformanceMeasuresDSE():\n",
    "    DSEdirectory = 'dataset/DSE/'\n",
    "    projectMetrics = []\n",
    "    index = 0\n",
    "    projectMetrics = pd.DataFrame(projectMetrics,\n",
    "                                    columns = ['Project','Precision', 'Recall', 'Auc_Score', 'Accuracy', 'Fmeasure', 'GMean'])\n",
    "    for projectName in os.listdir(DSEdirectory):\n",
    "        project = pd.read_csv(DSEdirectory + projectName)\n",
    "        projectData = project.as_matrix(columns=[\n",
    "                                         'DSE_Prediction',\n",
    "                                         'DSE_Pred_Prob',\n",
    "                                         'buggy'])\n",
    "      \n",
    "        row = []\n",
    "        row.append(projectName)\n",
    "        row.extend(computePerformanceMeasures(project['DSE_Prediction'], \n",
    "                                                         project['buggy'], \n",
    "                                                         project['DSE_Pred_Prob']))\n",
    "        projectMetrics.loc[index] = row\n",
    "        index = index + 1\n",
    "  \n",
    "    print(projectMetrics)\n",
    "    projectMetrics.to_csv('dataset/' + 'results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Project  Precision    Recall  Auc_Score  Accuracy  Fmeasure  \\\n",
      "0       camel-1.6.csv   0.700000  0.526882   0.784410  0.819945  0.601227   \n",
      "1      e-learning.csv   0.897959  0.897959   0.945874  0.929078  0.897959   \n",
      "2       intercafe.csv   0.833333  0.555556   0.928571  0.782609  0.666667   \n",
      "3         ivy-2.0.csv   0.894737  0.819277   0.939024  0.922297  0.855346   \n",
      "4       jedit-4.3.csv   0.926667  0.952055   0.971410  0.960526  0.939189   \n",
      "5      kalkulator.csv   0.666667  0.800000   0.885714  0.750000  0.727273   \n",
      "6       log4j-1.2.csv   0.974359  0.957983   0.989521  0.960784  0.966102   \n",
      "7      lucene-2.4.csv   0.699029  0.679245   0.735538  0.670051  0.688995   \n",
      "8         poi-2.5.csv   0.893258  0.903409   0.922172  0.865169  0.898305   \n",
      "9          prop-6.csv   0.803571  0.789474   0.916510  0.888530  0.796460   \n",
      "10       redaktor.csv   0.902439  0.725490   0.931373  0.867647  0.804348   \n",
      "11       serapion.csv   0.571429  0.571429   0.825714  0.812500  0.571429   \n",
      "12       sklebagd.csv   0.857143  0.857143   0.809524  0.800000  0.857143   \n",
      "13    synapse-1.2.csv   0.785714  0.478261   0.791142  0.884615  0.594595   \n",
      "14     systemdata.csv   0.600000  0.428571   0.835498  0.850000  0.500000   \n",
      "15    szybkafucha.csv   0.750000  0.900000   0.837500  0.777778  0.818182   \n",
      "16   termoproject.csv   0.571429  0.500000   0.846591  0.766667  0.533333   \n",
      "17         tomcat.csv   0.879518  0.682243   0.934793  0.930269  0.768421   \n",
      "18   velocity-1.6.csv   0.696970  0.534884   0.852478  0.788732  0.605263   \n",
      "19       workflow.csv   0.700000  0.777778   0.700855  0.772727  0.736842   \n",
      "20  wspomaganiepi.csv   1.000000  0.888889   0.944444  0.923077  0.941176   \n",
      "21      xalan-2.7.csv   0.965870  0.986063   0.998211  0.977492  0.975862   \n",
      "22     xerces-1.4.csv   0.920290  0.920290   0.916776  0.907173  0.920290   \n",
      "23          zuzel.csv   0.875000  0.777778   0.916667  0.823529  0.823529   \n",
      "\n",
      "       GMean  \n",
      "0   0.607303  \n",
      "1   0.897959  \n",
      "2   0.680414  \n",
      "3   0.856176  \n",
      "4   0.939275  \n",
      "5   0.730297  \n",
      "6   0.966136  \n",
      "7   0.689066  \n",
      "8   0.898319  \n",
      "9   0.796491  \n",
      "10  0.809142  \n",
      "11  0.571429  \n",
      "12  0.857143  \n",
      "13  0.613006  \n",
      "14  0.507093  \n",
      "15  0.821584  \n",
      "16  0.534522  \n",
      "17  0.774626  \n",
      "18  0.610572  \n",
      "19  0.737865  \n",
      "20  0.942809  \n",
      "21  0.975914  \n",
      "22  0.920290  \n",
      "23  0.824958  \n"
     ]
    }
   ],
   "source": [
    "computePerformanceMeasuresDSE()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mutationRate = 0.001\n",
    "crossOverRate = 0.001\n",
    "iterations = 10\n",
    "poolSize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roulette(fitness):\n",
    "    index = 0\n",
    "    cumalativeFitness = 0.0\n",
    "    r = random.random()\n",
    "    \n",
    "    for i in range(len(fitness)):\n",
    "        cumalativeFitness += fitness[i]\n",
    "        if cumalativeFitness > r:\n",
    "            return i\n",
    "\n",
    "\n",
    "def selectFittest(fitness, rankedPool):\n",
    "    while True:\n",
    "        idx1 = roulette(fitness)\n",
    "        idx2 = roulette(fitness)\n",
    "        \n",
    "        if idx1 is None or idx2 is None:\n",
    "            continue\n",
    "        elif idx1==idx2:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return rankedPool[idx1], rankedPool[idx2]\n",
    "\n",
    "def crossover(chrome1, chrome2):\n",
    "    randomSplitPoint = random.randint(1, len(chrome1))\n",
    "    return chrome1[:randomSplitPoint]+chrome2[randomSplitPoint:], chrome2[:randomSplitPoint]+chrome1[randomSplitPoint:]\n",
    "\n",
    "\n",
    "def mutate(chromosome):\n",
    "#     print chromosome\n",
    "    mutatedChrom = []\n",
    "    for ch in chromosome:\n",
    "        if random.random()<mutationRate:\n",
    "            if ch==1:\n",
    "                mutatedChrom.append(0)\n",
    "            else:\n",
    "                mutatedChrom.append(1)\n",
    "        else:\n",
    "            mutatedChrom.append(ch)\n",
    "    return mutatedChrom\n",
    "    \n",
    "def breed(chrome1, chrome2):\n",
    "    if random.random()<crossOverRate:\n",
    "        newChrome1, newChrome2 = crossover(chrome1, chrome2)\n",
    "    else:\n",
    "        newChrome1 = chrome1\n",
    "        newChrome2 = chrome2\n",
    "        \n",
    "    newChrome1 = mutate(newChrome1)\n",
    "    newChrome2 = mutate(newChrome2)\n",
    "    \n",
    "    return newChrome1, newChrome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rankPop(pool, X, y, classifier):\n",
    "    scores = []\n",
    "    \n",
    "    for chromosome in pool:\n",
    "#         print chromosome\n",
    "        chosen_idx = [idx for gene, idx in zip(chromosome, range(X.shape[1])) if gene==1]\n",
    "        if len(chosen_idx)==0:\n",
    "            continue\n",
    "        chosenX = X.iloc[:, chosen_idx]\n",
    "        \n",
    "        classifier.fit(chosenX, y)\n",
    "        scores.append(accuracy_score(y, classifier.predict(chosenX)))\n",
    "        \n",
    "    fitness = [x/sum(scores) for x in scores]\n",
    "    pairedPop = zip(pool, fitness)\n",
    "    rankedPop = sorted(pairedPop, key=itemgetter(-1), reverse = True)\n",
    "    \n",
    "    return rankedPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iteratePop(rankedPop):\n",
    "    fitness = [item[-1] for item in rankedPop]\n",
    "    rankedPool = [item[0] for item in rankedPop]\n",
    "   \n",
    "    new_pool = []\n",
    "    new_pool.extend(rankedPool[:poolSize/15])\n",
    "    \n",
    "    while(len(new_pool)<poolSize):\n",
    "        ch1, ch2 = selectFittest(fitness, rankedPool)\n",
    "        ch1, ch2 = breed(ch1, ch2)\n",
    "        \n",
    "        new_pool.append(ch1)\n",
    "        new_pool.append(ch2)\n",
    "    \n",
    "    return new_pool[:poolSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def geneticAlgoFit(datafile):\n",
    "    datafile = pd.read_csv(datafile, dtype={'buggy':np.bool})\n",
    "   \n",
    "    X     = datafile.iloc[ : , :-1]\n",
    "    y = datafile['buggy']\n",
    "    \n",
    "    classifier = RandomForestClassifier()\n",
    "  \n",
    "    pool = np.random.randint(0, 2, (poolSize, X.shape[1]))  \n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        rankedPop = rankPop(pool, X, y, classifier)\n",
    "        pool = []\n",
    "        pool = iteratePop(rankedPop)\n",
    "        \n",
    "    best_chromosome = rankPop(pool, X, y, classifier)[0][0]\n",
    "    return best_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0, 1, 0, 0], 0.022429332240884888), ([0, 0, 1, 1], 0.022429332240884888), ([1, 1, 1, 1], 0.022395193226819616), ([0, 1, 0, 0], 0.021780690973644688), ([0, 1, 0, 0], 0.021746551959579412), ([1, 1, 0, 1], 0.021678273931448867), ([0, 1, 1, 1], 0.021678273931448867), ([0, 1, 1, 1], 0.021644134917383592), ([1, 1, 0, 1], 0.021609995903318316), ([1, 1, 0, 1], 0.021609995903318316), ([0, 1, 0, 0], 0.021575856889253044), ([0, 1, 1, 1], 0.021507578861122496), ([0, 1, 0, 0], 0.021473439847057223), ([0, 1, 0, 0], 0.021473439847057223), ([0, 1, 0, 0], 0.021405161818926675), ([0, 1, 0, 0], 0.021405161818926675), ([0, 1, 1, 1], 0.021234466748600307), ([0, 1, 0, 1], 0.020995493650143388), ([0, 0, 1, 1], 0.020415130411033735), ([0, 1, 0, 0], 0.020346852382903187), ([0, 0, 0, 0], 0.020346852382903187), ([1, 1, 0, 1], 0.020346852382903187), ([1, 1, 0, 1], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([1, 1, 1, 1], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([1, 1, 0, 1], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([0, 1, 1, 1], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([0, 1, 0, 0], 0.020346852382903187), ([0, 0, 1, 1], 0.020346852382903187), ([0, 0, 0, 0], 0.020346852382903187), ([1, 1, 0, 1], 0.020346852382903187), ([0, 1, 0, 0], 0.020312713368837915), ([0, 1, 0, 0], 0.020312713368837915), ([0, 1, 0, 0], 0.020312713368837915), ([0, 1, 0, 0], 0.020312713368837915), ([0, 0, 1, 1], 0.020312713368837915), ([0, 1, 0, 0], 0.020312713368837915), ([0, 1, 0, 0], 0.020312713368837915), ([0, 1, 0, 0], 0.020312713368837915), ([0, 1, 0, 0], 0.020278574354772639), ([1, 1, 0, 1], 0.020278574354772639), ([1, 1, 1, 1], 0.020278574354772639), ([1, 0, 1, 1], 0.020278574354772639)]\n",
      "[0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "datafile = 'dataset/dataset/camel-1.6.csv'\n",
    "print geneticAlgoFit(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. IN pred_util function instead of directly training the data train on selected featured by geneticAlgoFit\n",
    "2. Set the parameters for GA.\n",
    "3. Remaining process remains same having 3 ensembles and 1 fitness function\n",
    "4. To be used without WEKA\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
