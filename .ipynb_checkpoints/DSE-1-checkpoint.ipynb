{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = GaussianNB()\n",
    "from sklearn.metrics import precision_score\n",
    "clf4=MLPClassifier(max_iter=1000)\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('gnb', clf3)],voting='soft')\n",
    "import os\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "clf = RandomForestClassifier()#max_depth=1, random_state=0,n_estimators=10)\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada=AdaBoostClassifier(n_estimators=50)#n_estimators=10)\n",
    "ada.n_estimators\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file1,classifier):\n",
    "    #file1=pd.read_csv('C:/Users/DELL/Desktop/final/arc.csv' , dtype={'bug_binarized':np.bool})\n",
    "    #print file1.columns.values\n",
    "    cols=file1.columns\n",
    "    #print cols\n",
    "    if classifier==eclf:\n",
    "        cols=cols[:-1]\n",
    "        X=file1.iloc[:,:-1]\n",
    "        X1=file1.as_matrix(cols)\n",
    "    elif classifier==ada:\n",
    "        cols=cols[:-3]\n",
    "        X=file1.iloc[:,:-3]\n",
    "        X1=file1.as_matrix(cols)\n",
    "    else:\n",
    "        cols=cols[:-5]\n",
    "        X=file1.iloc[:,:-5]\n",
    "        X1=file1.as_matrix(cols)\n",
    "    y=file1['bug_binarized']\n",
    "    #print X.head()\n",
    "    Y=np.array(y)\n",
    "    kf = KFold(n_splits=file1.shape[0])\n",
    "    kf.get_n_splits(X)\n",
    "    train=[]\n",
    "    test=[]\n",
    "    ans_arr=[]\n",
    "    arr_prob=[]\n",
    "    ans=0\n",
    "    k=0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if classifier==ada:\n",
    "            classifier=AdaBoostClassifier(n_estimators=50)\n",
    "        elif classifier==eclf:\n",
    "            classifier=VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('gnb', clf3)],voting='soft')\n",
    "        else:\n",
    "            classifier=RandomForestClassifier()\n",
    "        for i in train_index:\n",
    "            train.append(X1[i])\n",
    "            test.append(y[i])\n",
    "        classifier.fit(train,test)\n",
    "        ans_arr.append(classifier.predict(X1[test_index]))\n",
    "        arr_prob.append(classifier.predict_proba(X1[test_index]))\n",
    "        train=[]\n",
    "        test=[]\n",
    "    answer=[]\n",
    "    for i in range(len(arr_prob)):\n",
    "        answer.append(arr_prob[i][0][1])\n",
    "    #print(\"LOLOLOL\",roc_auc_score(y_true=Y,y_score=answer))#,y=ans_arr))\n",
    "    return ans_arr,y,arr_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def f1():\n",
    "    #filename='zuzel.csv'\n",
    "    #print filename\n",
    "    file1=pd.read_csv('C:/Users/DELL/Desktop/fold/'+filename , dtype={'bug_binarized':np.bool})\n",
    "    clf1=LogisticRegression()\n",
    "    clf2=DecisionTreeClassifier()\n",
    "    clf3=GaussianNB()\n",
    "    eclf=VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('gnb', clf3)],voting='soft')\n",
    "    ada=AdaBoostClassifier()\n",
    "    rf=RandomForestClassifier(n_estimators=10)\n",
    "    y=[]\n",
    "    ans_arr,y,arr_prob=predict(file1,eclf)\n",
    "    arrnew=[]\n",
    "    for i in range(len(ans_arr)):\n",
    "        if ans_arr[i][0]==True:\n",
    "            arrnew.append(True)\n",
    "        else:\n",
    "            arrnew.append(False)\n",
    "    file1['Voting_Prediction']=arrnew\n",
    "    arrnew=[]\n",
    "    for i in range(len(ans_arr)):\n",
    "        arrnew.append(arr_prob[i][0][1])\n",
    "    file1['Voting_Prediction_Prob']=arrnew\n",
    "    arr_prob=np.array(arr_prob)\n",
    "    precision=precision_score(y_true=y,y_pred=ans_arr)\n",
    "    recall=recall_score(y_true=y,y_pred=ans_arr)\n",
    "    score=roc_auc_score(y,arrnew)\n",
    "    accuracy=accuracy_score(y_pred=ans_arr,y_true=y)\n",
    "    f_measure=2*(precision*recall)/float(precision+recall)\n",
    "    text_file.write('\\n'+filename+','+'Voting'+','+str(precision)+','+str(recall)+','+str(accuracy)+','+str(f_measure)+','+\n",
    "                    str(score))\n",
    "    #y=np.array(y)\n",
    "    #y=list(y)\n",
    "    #plot_confusion_matrix(cm=confusion_matrix(y_true=y,y_pred=ans_arr),classes=['Non Defective','Defective'],\n",
    "                         # filename=filename)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(ans_arr,arrnew, pos_label=True)\n",
    "    #print fpr,tpr,thresholds\n",
    "    #---AdaBOOST HERE----\n",
    "    \n",
    "    ans_arr,y,arr_prob=predict(file1,ada)\n",
    "    arrnew=[]\n",
    "    for i in range(len(ans_arr)):\n",
    "        if ans_arr[i][0]==True:\n",
    "            arrnew.append(True)\n",
    "        else:\n",
    "            arrnew.append(False)\n",
    "    file1['AdaBoost_Prediction']=arrnew\n",
    "    arrnew=[]\n",
    "    for i in range(len(ans_arr)):\n",
    "        arrnew.append(arr_prob[i][0][1])\n",
    "    file1['AdaBoost_Prediction_Prob']=arrnew\n",
    "    arr_prob=np.array(arr_prob)\n",
    "    precision=precision_score(y_true=y,y_pred=ans_arr)\n",
    "    recall=recall_score(y_true=y,y_pred=ans_arr)\n",
    "    score=roc_auc_score(y,arrnew)\n",
    "    accuracy=accuracy_score(y_pred=ans_arr,y_true=y)\n",
    "    f_measure=2*(precision*recall)/float(precision+recall)\n",
    "    \n",
    "    text_file.write('\\n'+filename+','+'AdaBoost'+','+str(precision)+','+str(recall)+','+str(accuracy)+','+str(f_measure)+','+\n",
    "                    str(score))\n",
    "    y=np.array(y)\n",
    "#---RANDOM FOREST HERE---------\n",
    "\n",
    "    rf=RandomForestClassifier()\n",
    "    ans_arr,y,arr_prob=predict(file1,rf)\n",
    "    arrnew=[]\n",
    "    for i in range(len(ans_arr)):\n",
    "        if ans_arr[i][0]==True:\n",
    "            arrnew.append(True)\n",
    "        else:\n",
    "            arrnew.append(False)\n",
    "    file1['RandomForest_Prediction']=arrnew\n",
    "    arrnew=[]\n",
    "    for i in range(len(ans_arr)):\n",
    "        arrnew.append(arr_prob[i][0][1])\n",
    "    file1['RandomForest_Prediction_Prob']=arrnew\n",
    "    arr_prob=np.array(arr_prob)\n",
    "    precision=precision_score(y_true=y,y_pred=ans_arr)\n",
    "    recall=recall_score(y_true=y,y_pred=ans_arr)\n",
    "    score=roc_auc_score(y,arrnew)\n",
    "    accuracy=accuracy_score(y_pred=ans_arr,y_true=y)\n",
    "    f_measure=2*(precision*recall)/float(precision+recall)\n",
    "    text_file.write('\\n'+filename+','+'Random Forest'+','+str(precision)+','+str(recall)+','+str(accuracy)+','+str(f_measure)+','+\n",
    "                    str(score))\n",
    "\n",
    "    confusion_matrix(y_true=y,y_pred=ans_arr)\n",
    "    #file1.to_csv('C:/Users/DELL/Desktop/fold/'+filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
