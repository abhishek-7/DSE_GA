{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#importing base learners of Voting Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Importing three component ensembles\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#importing SVC for second-step classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining ml techniques\n",
    "base_learner1 = LogisticRegression(random_state=1)\n",
    "base_learner2 = DecisionTreeClassifier()\n",
    "base_learner3 = GaussianNB()\n",
    "\n",
    "ensemble1 = VotingClassifier(estimators=[('logregression', base_learner1), \n",
    "                                         ('dtree', base_learner2), \n",
    "                                         ('gnb', base_learner3)], \n",
    "                                          voting='soft')\n",
    "ensemble2 = RandomForestClassifier()\n",
    "ensemble3 = AdaBoostClassifier(n_estimators=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts bug and their probabilities for given datafile and classifier pair\n",
    "\n",
    "def predict_util(datafile, classifier):\n",
    "    ncols = datafile.columns\n",
    "    #extracting relevant columns, software metrics in X, and labels in Y\n",
    "    if classifier == ensemble1:\n",
    "        ncols = ncols[ :-1]\n",
    "        X     = datafile.iloc[ : , :-1]\n",
    "        X1    = datafile.as_matrix(ncols)\n",
    "    elif classifier == ensemble2:\n",
    "        ncols = ncols[ :-3]\n",
    "        X     = datafile.iloc[ : , :-3]\n",
    "        X1    = datafile.as_matrix(ncols)\n",
    "    else:\n",
    "        ncols = ncols[ :-5]\n",
    "        X     = datafile.iloc[ : , :-5]\n",
    "        X1    = datafile.as_matrix(ncols)\n",
    "    y = datafile['bug_binarized']\n",
    "    Y = np.array(y)\n",
    "    \n",
    "    #performing leave-one out validation for instances less than 100\n",
    "    #and 10 fold validation for others\n",
    "    npoints = X.shape[0]\n",
    "   \n",
    "    if npoints <= 100:\n",
    "        kf = KFold(n_splits = npoints)\n",
    "    else:\n",
    "        kf = KFold(n_splits = 10)\n",
    "        \n",
    "    kf.get_n_splits(X)\n",
    "    train_X = []\n",
    "    train_Y  = []\n",
    "    prediction   = []\n",
    "    predict_prob = [] \n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        if classifier == ensemble1:\n",
    "            classifier = VotingClassifier(estimators=[('logregression', base_learner1), \n",
    "                                         ('dtree', base_learner2), \n",
    "                                         ('gnb', base_learner3)], \n",
    "                                          voting='soft')      \n",
    "        elif classifier == ensemble2:\n",
    "            classifier = RandomForestClassifier()\n",
    "        else:\n",
    "            classifier = AdaBoostClassifier(n_estimators=50)\n",
    "            \n",
    "\n",
    "        for i in train_index:\n",
    "                train_X.append(X1[i])\n",
    "                train_Y.append(Y[i])\n",
    "        \n",
    "        classifier.fit(train_X, train_Y)\n",
    "        \n",
    "        for j in test_index:\n",
    "            prediction.append(classifier.predict([X1[j]])[0])\n",
    "            predict_prob.append(classifier.predict_proba([X1[j]])[0][1])\n",
    "        \n",
    "        train_X  = []\n",
    "        train_Y  = []\n",
    "        \n",
    "    return prediction, Y, predict_prob\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file=pd.read_csv('dataset/dataset/camel-1.6.csv' , dtype={'bug_binarized':np.bool})\n",
    "#predict_util(file, ensemble3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasures(predictions, labels, prediction_probability):\n",
    "    \n",
    "    precision = precision_score(y_true=labels, y_pred=predictions)\n",
    "    recall    = recall_score(y_true=labels, y_pred=predictions)\n",
    "    roc_score = roc_auc_score(labels, prediction_probability)\n",
    "    accuracy  = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "    f_measure = 2*(precision*recall)/float(precision+recall) \n",
    "    \n",
    "    metrics = [precision, recall, roc_score, accuracy, f_measure]\n",
    "    \n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    directory = 'dataset/dataset/'\n",
    "    \n",
    "    for projectName in os.listdir(directory):\n",
    "        performanceMetrics = []\n",
    "    \n",
    "        projectData = pd.read_csv(directory + projectName, dtype={'bug_binarized':np.bool})\n",
    "        \n",
    "        metricsFrame = pd.DataFrame(performanceMetrics, \n",
    "                                    index = ['Precision', 'Recall', 'Auc_Score', 'Accuracy', 'F_Measure'])\n",
    "        \n",
    "        predictionEnsemble1, YEnsemble1, predict_probEnsemble1 = predict_util(projectData, ensemble1)\n",
    "        projectData['Voting_Prediction'] = predictionEnsemble1\n",
    "        projectData['Voting_Pred_Prob']  = predict_probEnsemble1\n",
    "        VotingMetrics = computePerformanceMeasures(predictionEnsemble1, YEnsemble1, predict_probEnsemble1)\n",
    "\n",
    "        metricsFrame.insert(loc = 0, column = 'Voting', value = VotingMetrics)\n",
    "                \n",
    "        predictionEnsemble2, YEnsemble2, predict_probEnsemble2 = predict_util(projectData, ensemble2)\n",
    "        projectData['RandomForest_Prediction'] = predictionEnsemble2\n",
    "        projectData['RandomForest_Pred_Prob']  = predict_probEnsemble2\n",
    "        RandomForestMetrics = computePerformanceMeasures(predictionEnsemble2, YEnsemble2, predict_probEnsemble2)\n",
    "        metricsFrame.insert(loc=1, column='RandomForest', value = RandomForestMetrics)\n",
    "        \n",
    "        predictionEnsemble3, YEnsemble3, predict_probEnsemble3 = predict_util(projectData, ensemble3)\n",
    "        projectData['AdaBoost_Prediction'] = predictionEnsemble3\n",
    "        projectData['AdaBoost_Pred_Prob']  = predict_probEnsemble3\n",
    "        AdaBoostMetrics = computePerformanceMeasures(predictionEnsemble2, YEnsemble2, predict_probEnsemble2)\n",
    "        metricsFrame.insert(loc=2, column='AdaBoost', value = AdaBoostMetrics)\n",
    "        \n",
    "        metricsFrame.to_csv('dataset/metrics/' + projectName)\n",
    "\n",
    "        projectData.to_csv('dataset/annotated/' + projectName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestEnsembleSelector():\n",
    "    annotated_directory   = 'dataset/annotated/'\n",
    "    performance_directory = 'dataset/metrics/'\n",
    "\n",
    "    for projectName in os.listdir(annotated_directory):\n",
    "        print(projectName)\n",
    "        annotatedData = pd.read_csv(annotated_directory + projectName, dtype={'bug_binarized':np.bool})\n",
    "        metricData    = pd.read_csv(performance_directory + projectName)\n",
    "\n",
    "\n",
    "        predictionMatrix = annotatedData.as_matrix(columns = ['bug_binarized','Voting_Prediction','AdaBoost_Prediction','RandomForest_Prediction'])\n",
    "        print(metricData)\n",
    "        print(metricData.loc[0, 'Voting'])\n",
    "        \n",
    "       # defining constants\n",
    "        f_measure_constant    = 4     # f-measure is at the 4th row\n",
    "        auc_score_constant    = 2     # auc_score is at the 2nd row\n",
    "        voting_constant       = 'Voting'\n",
    "        adaBoost_constant     = 'AdaBoost'\n",
    "        randomForest_constant = 'RandomForest'\n",
    "        \n",
    "        ensemble=[]\n",
    "        \n",
    "        for i in range(len(predictionMatrix)):\n",
    "            if   predictionMatrix[i][0] == predictionMatrix[i][1] and predictionMatrix[i][0] != predictionMatrix[i][2] and predictionMatrix[i][0] != predictionMatrix[i][3]:\n",
    "                ensemble.append('Voting')\n",
    "            elif predictionMatrix[i][0] == predictionMatrix[i][2] and predictionMatrix[i][0] != predictionMatrix[i][1] and predictionMatrix[i][0] != predictionMatrix[i][3]:\n",
    "                ensemble.append('AdaBoost')\n",
    "            elif predictionMatrix[i][0] == predictionMatrix[i][3] and predictionMatrix[i][0] != predictionMatrix[i][1] and predictionMatrix[i][0] != predictionMatrix[i][2]:\n",
    "                ensemble.append('RandomForest')\n",
    "            else:\n",
    "                f_voting       = metricData.loc[f_measure_constant, voting_constant]\n",
    "                f_adaboost     = metricData.loc[f_measure_constant, adaBoost_constant]\n",
    "                f_randomForest = metricData.loc[f_measure_constant, randomForest_constant]\n",
    "                flag=True\n",
    "                if f_voting > f_adaboost and f_voting > f_randomForest:\n",
    "                    ensemble.append('Voting')\n",
    "                    flag=False\n",
    "                elif f_adaboost > f_randomForest and f_randomForest > f_voting:\n",
    "                    ensemble.append('AdaBoost')\n",
    "                    flag=False\n",
    "                else:\n",
    "                    ensemble.append('RandomForest')\n",
    "                    flag=False\n",
    "            if flag == True:\n",
    "                p_voting       = metricData[auc_score_constant][voting_constant]\n",
    "                p_adaBoost     = metricData[auc_score_constant][adaBoost_constant]\n",
    "                p_randomForest = metricData[auc_score_constant][randomForest_constant]\n",
    "\n",
    "                if p_voting > p_adaBoost and p_voting > p_randomForest:\n",
    "                    ensemble.append('Voting')\n",
    "                    flag=False\n",
    "\n",
    "                elif p_adaBoost>p_randomForest and p_adaBoost>p_voting:\n",
    "                    ensemble.append('AdaBoost')\n",
    "                    flag=False\n",
    "\n",
    "                else:\n",
    "                    ensemble.append('RandomForest')\n",
    "                    flag=False\n",
    "            if flag == True:\n",
    "                ensemble.append('Voting')\n",
    "                \n",
    "        annotatedData['selectedEnsemble'] = ensemble\n",
    "        annotatedData.to_csv(annotated_directory + projectName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.718750      0.750000  0.750000\n",
      "1     Recall  0.370968      0.354839  0.354839\n",
      "2  Auc_Score  0.723068      0.730290  0.730290\n",
      "3   Accuracy  0.800554      0.803324  0.803324\n",
      "4  F_Measure  0.489362      0.481752  0.481752\n",
      "0.71875\n",
      "e-learning.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.833333      0.812500  0.812500\n",
      "1     Recall  0.816327      0.795918  0.795918\n",
      "2  Auc_Score  0.909605      0.899290  0.899290\n",
      "3   Accuracy  0.879433      0.865248  0.865248\n",
      "4  F_Measure  0.824742      0.804124  0.804124\n",
      "0.8333333333333334\n",
      "intercafe.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.666667      0.666667  0.666667\n",
      "1     Recall  0.666667      0.666667  0.666667\n",
      "2  Auc_Score  0.746032      0.746032  0.746032\n",
      "3   Accuracy  0.739130      0.739130  0.739130\n",
      "4  F_Measure  0.666667      0.666667  0.666667\n",
      "0.6666666666666666\n",
      "ivy-2.0.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.765432      0.753623  0.753623\n",
      "1     Recall  0.746988      0.626506  0.626506\n",
      "2  Auc_Score  0.887833      0.849652  0.849652\n",
      "3   Accuracy  0.864865      0.837838  0.837838\n",
      "4  F_Measure  0.756098      0.684211  0.684211\n",
      "0.7654320987654321\n",
      "jedit-4.3.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.800000      0.831858  0.831858\n",
      "1     Recall  0.657534      0.643836  0.643836\n",
      "2  Auc_Score  0.939074      0.952740  0.952740\n",
      "3   Accuracy  0.837719      0.844298  0.844298\n",
      "4  F_Measure  0.721805      0.725869  0.725869\n",
      "0.8\n",
      "kalkulator.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.727273      0.666667  0.666667\n",
      "1     Recall  0.800000      0.800000  0.800000\n",
      "2  Auc_Score  0.792857      0.792857  0.792857\n",
      "3   Accuracy  0.791667      0.750000  0.750000\n",
      "4  F_Measure  0.761905      0.727273  0.727273\n",
      "0.7272727272727273\n",
      "log4j-1.2.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.932203      0.932773  0.932773\n",
      "1     Recall  0.924370      0.932773  0.932773\n",
      "2  Auc_Score  0.957291      0.964409  0.964409\n",
      "3   Accuracy  0.916667      0.921569  0.921569\n",
      "4  F_Measure  0.928270      0.932773  0.932773\n",
      "0.9322033898305084\n",
      "lucene-2.4.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.634615      0.640000  0.640000\n",
      "1     Recall  0.622642      0.603774  0.603774\n",
      "2  Auc_Score  0.617562      0.628032  0.628032\n",
      "3   Accuracy  0.604061      0.604061  0.604061\n",
      "4  F_Measure  0.628571      0.621359  0.621359\n",
      "0.6346153846153846\n",
      "poi-2.5.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.861111      0.855556  0.855556\n",
      "1     Recall  0.880682      0.875000  0.875000\n",
      "2  Auc_Score  0.889610      0.876686  0.876686\n",
      "3   Accuracy  0.827715      0.820225  0.820225\n",
      "4  F_Measure  0.870787      0.865169  0.865169\n",
      "0.8611111111111112\n",
      "prop-6.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.666667      0.697987  0.697987\n",
      "1     Recall  0.608187      0.608187  0.608187\n",
      "2  Auc_Score  0.829032      0.842614  0.842614\n",
      "3   Accuracy  0.807754      0.819063  0.819063\n",
      "4  F_Measure  0.636086      0.650000  0.650000\n",
      "0.6666666666666666\n",
      "redaktor.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.933333      0.933333  0.933333\n",
      "1     Recall  0.823529      0.823529  0.823529\n",
      "2  Auc_Score  0.930104      0.929642  0.929642\n",
      "3   Accuracy  0.911765      0.911765  0.911765\n",
      "4  F_Measure  0.875000      0.875000  0.875000\n",
      "0.9333333333333332\n",
      "serapion.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.428571      0.428571  0.428571\n",
      "1     Recall  0.428571      0.428571  0.428571\n",
      "2  Auc_Score  0.691429      0.714286  0.714286\n",
      "3   Accuracy  0.750000      0.750000  0.750000\n",
      "4  F_Measure  0.428571      0.428571  0.428571\n",
      "0.42857142857142855\n",
      "sklebagd.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.833333      0.833333  0.833333\n",
      "1     Recall  0.714286      0.714286  0.714286\n",
      "2  Auc_Score  0.476190      0.523810  0.523810\n",
      "3   Accuracy  0.700000      0.700000  0.700000\n",
      "4  F_Measure  0.769231      0.769231  0.769231\n",
      "0.8333333333333334\n",
      "synapse-1.2.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.400000      0.421053  0.421053\n",
      "1     Recall  0.347826      0.347826  0.347826\n",
      "2  Auc_Score  0.682852      0.669850  0.669850\n",
      "3   Accuracy  0.792308      0.800000  0.800000\n",
      "4  F_Measure  0.372093      0.380952  0.380952\n",
      "0.4\n",
      "systemdata.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.600000      0.600000  0.600000\n",
      "1     Recall  0.428571      0.428571  0.428571\n",
      "2  Auc_Score  0.757576      0.757576  0.757576\n",
      "3   Accuracy  0.850000      0.850000  0.850000\n",
      "4  F_Measure  0.500000      0.500000  0.500000\n",
      "0.6\n",
      "szybkafucha.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  1.000000      0.900000  0.900000\n",
      "1     Recall  0.900000      0.900000  0.900000\n",
      "2  Auc_Score  0.900000      0.900000  0.900000\n",
      "3   Accuracy  0.944444      0.888889  0.888889\n",
      "4  F_Measure  0.947368      0.900000  0.900000\n",
      "1.0\n",
      "termoproject.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.333333      0.333333  0.333333\n",
      "1     Recall  0.375000      0.375000  0.375000\n",
      "2  Auc_Score  0.602273      0.607955  0.607955\n",
      "3   Accuracy  0.633333      0.633333  0.633333\n",
      "4  F_Measure  0.352941      0.352941  0.352941\n",
      "0.3333333333333333\n",
      "tomcat.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.779070      0.776471  0.776471\n",
      "1     Recall  0.626168      0.616822  0.616822\n",
      "2  Auc_Score  0.860455      0.879174  0.879174\n",
      "3   Accuracy  0.906498      0.904913  0.904913\n",
      "4  F_Measure  0.694301      0.687500  0.687500\n",
      "0.7790697674418605\n",
      "velocity-1.6.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.636364      0.617647  0.617647\n",
      "1     Recall  0.488372      0.488372  0.488372\n",
      "2  Auc_Score  0.757106      0.781771  0.781771\n",
      "3   Accuracy  0.760563      0.753521  0.753521\n",
      "4  F_Measure  0.552632      0.545455  0.545455\n",
      "0.6363636363636364\n",
      "workflow.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.700000      0.700000  0.700000\n",
      "1     Recall  0.777778      0.777778  0.777778\n",
      "2  Auc_Score  0.606838      0.623932  0.623932\n",
      "3   Accuracy  0.772727      0.772727  0.772727\n",
      "4  F_Measure  0.736842      0.736842  0.736842\n",
      "0.7\n",
      "wspomaganiepi.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.875000      0.875000  0.875000\n",
      "1     Recall  0.777778      0.777778  0.777778\n",
      "2  Auc_Score  0.583333      0.583333  0.583333\n",
      "3   Accuracy  0.769231      0.769231  0.769231\n",
      "4  F_Measure  0.823529      0.823529  0.823529\n",
      "0.875\n",
      "xalan-2.7.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.992933      0.992832  0.992832\n",
      "1     Recall  0.979094      0.965157  0.965157\n",
      "2  Auc_Score  0.989786      0.982235  0.982235\n",
      "3   Accuracy  0.987138      0.980707  0.980707\n",
      "4  F_Measure  0.985965      0.978799  0.978799\n",
      "0.9929328621908128\n",
      "xerces-1.4.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.902778      0.902778  0.902778\n",
      "1     Recall  0.942029      0.942029  0.942029\n",
      "2  Auc_Score  0.919924      0.919265  0.919265\n",
      "3   Accuracy  0.907173      0.907173  0.907173\n",
      "4  F_Measure  0.921986      0.921986  0.921986\n",
      "0.9027777777777778\n",
      "zuzel.csv\n",
      "  Unnamed: 0    Voting  RandomForest  AdaBoost\n",
      "0  Precision  0.875000      0.875000  0.875000\n",
      "1     Recall  0.777778      0.777778  0.777778\n",
      "2  Auc_Score  0.763889      0.777778  0.777778\n",
      "3   Accuracy  0.823529      0.823529  0.823529\n",
      "4  F_Measure  0.823529      0.823529  0.823529\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "bestEnsembleSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camel-1.6.csv', 0.75, 0.3870967741935484, 0.7417850264805006, 0.8088642659279779, 0.5106382978723403]\n",
      "['e-learning.csv', 0.8333333333333334, 0.8163265306122449, 0.9096051464063887, 0.8794326241134752, 0.8247422680412372]\n",
      "['intercafe.csv', 0.6666666666666666, 0.6666666666666666, 0.746031746031746, 0.7391304347826086, 0.6666666666666666]\n",
      "['ivy-2.0.csv', 0.7777777777777778, 0.7590361445783133, 0.9023134792691895, 0.8716216216216216, 0.7682926829268293]\n",
      "['jedit-4.3.csv', 0.8392857142857143, 0.6438356164383562, 0.9558329650905877, 0.8464912280701754, 0.7286821705426357]\n",
      "['kalkulator.csv', 0.7272727272727273, 0.8, 0.7928571428571429, 0.7916666666666666, 0.761904761904762]\n",
      "['log4j-1.2.csv', 0.9327731092436975, 0.9327731092436975, 0.9644092931290164, 0.9215686274509803, 0.9327731092436976]\n",
      "['lucene-2.4.csv', 0.6504854368932039, 0.6320754716981132, 0.6431681526021149, 0.6192893401015228, 0.6411483253588518]\n",
      "['poi-2.5.csv', 0.861878453038674, 0.8863636363636364, 0.8929820179820179, 0.8314606741573034, 0.8739495798319329]\n",
      "['prop-6.csv', 0.7019867549668874, 0.6198830409356725, 0.851294903926483, 0.8222940226171244, 0.6583850931677019]\n",
      "['redaktor.csv', 0.9333333333333333, 0.8235294117647058, 0.9296424452133795, 0.9117647058823529, 0.8749999999999999]\n",
      "['serapion.csv', 0.5, 0.5714285714285714, 0.72, 0.78125, 0.5333333333333333]\n",
      "['sklebagd.csv', 0.8333333333333334, 0.7142857142857143, 0.523809523809524, 0.7, 0.7692307692307692]\n",
      "['synapse-1.2.csv', 0.45, 0.391304347826087, 0.7080455099553027, 0.8076923076923077, 0.4186046511627907]\n",
      "['systemdata.csv', 0.6, 0.42857142857142855, 0.7575757575757576, 0.85, 0.5]\n",
      "['szybkafucha.csv', 1.0, 0.9, 0.9, 0.9444444444444444, 0.9473684210526316]\n",
      "['termoproject.csv', 0.3333333333333333, 0.375, 0.6079545454545454, 0.6333333333333333, 0.35294117647058826]\n",
      "['tomcat.csv', 0.7865168539325843, 0.6542056074766355, 0.8850146250980953, 0.9112519809825673, 0.7142857142857143]\n",
      "['velocity-1.6.csv', 0.6666666666666666, 0.5116279069767442, 0.7881136950904393, 0.7746478873239436, 0.5789473684210527]\n",
      "['workflow.csv', 0.7, 0.7777777777777778, 0.6239316239316239, 0.7727272727272727, 0.7368421052631577]\n",
      "['wspomaganiepi.csv', 0.875, 0.7777777777777778, 0.5833333333333334, 0.7692307692307693, 0.823529411764706]\n",
      "['xalan-2.7.csv', 0.9929328621908127, 0.9790940766550522, 0.9897862603359509, 0.9871382636655949, 0.9859649122807017]\n",
      "['xerces-1.4.csv', 0.9027777777777778, 0.9420289855072463, 0.919265114917289, 0.9071729957805907, 0.9219858156028369]\n",
      "['zuzel.csv', 0.875, 0.7777777777777778, 0.7777777777777778, 0.8235294117647058, 0.823529411764706]\n"
     ]
    }
   ],
   "source": [
    "def computePerformanceMeasuresDSE():\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    for projectName in os.listdir(annotated_directory):\n",
    "        DSEPrediction = []\n",
    "        predict_prob  = []\n",
    "        annotatedProject = pd.read_csv(annotated_directory + projectName)\n",
    "        annotatedProjectData = annotatedProject.as_matrix(columns=[\n",
    "                                         'Voting_Prediction',\n",
    "                                         'Voting_Pred_Prob',\n",
    "                                         'AdaBoost_Prediction',\n",
    "                                         'AdaBoost_Pred_Prob',\n",
    "                                         'RandomForest_Prediction',\n",
    "                                         'RandomForest_Pred_Prob'])\n",
    "        ensemble = np.array(annotatedProject['selectedEnsemble'])\n",
    "        \n",
    "        prediction_constant = '_Prediction'\n",
    "        probab_constant     = '_Pred_Prob'\n",
    "        \n",
    "        for i in range(len(ensemble)):\n",
    "            DSEPrediction.append(annotatedProject.loc[i, ensemble[i] + prediction_constant])\n",
    "            predict_prob.append(annotatedProject.loc[i, ensemble[i] + probab_constant])\n",
    "            \n",
    "        annotatedProject['DSE_Prediction'] = DSEPrediction\n",
    "        annotatedProject['DSE_Pred_Prob']  = predict_prob\n",
    "        projectMetrics = []\n",
    "        projectMetrics.append(projectName)\n",
    "        projectMetrics.extend(computePerformanceMeasures(DSEPrediction, annotatedProject['bug_binarized'], predict_prob))\n",
    "        print(projectMetrics)\n",
    "#         metrics = [precision, recall, roc_score, accuracy, f_measure]\n",
    "#         DSEmetricsFrame = pd.DataFrame(performanceMetrics, \n",
    "#                                     index = ['Precision', 'Recall', 'Auc_Score', 'Accuracy', 'F_Measure'])\n",
    "                \n",
    "computePerformanceMeasuresDSE()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svctrain():\n",
    "    directory = 'dataset/dataset/'\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    for projectName in os.listdir(directory):\n",
    "        print(projectName)\n",
    "        projectData = pd.read_csv(directory + projectName)\n",
    "        annotatedData = pd.read_csv(annotated_directory + projectName)\n",
    "        \n",
    "        #X contains software metrics and Y best ensemble selected\n",
    "        X = np.array(projectData.iloc[ : ,0:-1])\n",
    "        Y = np.array(annotatedData.iloc[ : ,-1])\n",
    "        \n",
    "        npoints = X.shape[0]\n",
    "        \n",
    "        if npoints <= 100:\n",
    "            kf = KFold(n_splits = npoints)\n",
    "        else:\n",
    "            kf = KFold(n_splits = 10)\n",
    "        \n",
    "        kf.get_n_splits(X)\n",
    "        train_X = []\n",
    "        train_Y  = []\n",
    "        predictedEnsemble = []\n",
    "        predict_prob = [] \n",
    "    \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            classifier = SVC()\n",
    "            \n",
    "            for i in train_index:\n",
    "                train_X.append(X[i])\n",
    "                train_Y.append(Y[i])\n",
    "            \n",
    "            unique_labels = np.unique(train_Y)\n",
    "            if unique_labels.size == 1:\n",
    "                for j in test_index:\n",
    "                    predictedEnsemble.append(unique_labels[0])\n",
    "                #predict_prob.append(classifier.predict_proba([X1[j]])[0])\n",
    "            \n",
    "           \n",
    "            else:\n",
    "                classifier.fit(train_X, train_Y)\n",
    "            \n",
    "                for j in test_index:\n",
    "                    predictedEnsemble.append(classifier.predict([X[j]])[0])\n",
    "               # predict_prob.append(classifier.predict_proba([X1[j]])[0])\n",
    "                    print(classifier.predict_proba([X[j]]))\n",
    "            \n",
    "        print(predictedEnsemble)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-5e3ace041fc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msvctrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-cf96fe8380da>\u001b[0m in \u001b[0;36msvctrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0mpredictedEnsemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                \u001b[1;31m# predict_prob.append(classifier.predict_proba([X1[j]])[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lololol\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictedEnsemble\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \"\"\"\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    558\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "svctrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
