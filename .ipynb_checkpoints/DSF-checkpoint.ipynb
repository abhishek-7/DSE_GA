{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Importing three component ensembles\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#importing SVC for second-step classification\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutationRate = 0.001\n",
    "crossOverRate = 0.06\n",
    "iterations = 20\n",
    "poolSize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions for genetic algorithms\n",
    "\n",
    "def roulette(fitnessArray):\n",
    "    index = 0\n",
    "    mex = sum([c for c in fitnessArray])\n",
    "    pick = random.uniform(0,mex)\n",
    "    current = 0\n",
    "    \n",
    "    for i in range(len(fitnessArray)):\n",
    "        current += fitnessArray[i]\n",
    "        if current > pick:\n",
    "            return i\n",
    "\n",
    "\n",
    "def selectFittest(fitness, rankedPool):\n",
    "    while True:\n",
    "        idx1 = roulette(fitness)\n",
    "        idx2 = roulette(fitness)\n",
    "        \n",
    "        if idx1 is None or idx2 is None:\n",
    "            continue\n",
    "        elif idx1==idx2:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return rankedPool[idx1], rankedPool[idx2]\n",
    "\n",
    "def crossover(chromosome1, chromosome2):\n",
    "    randomSplitPoint = random.randint(1, len(chromosome1))\n",
    "    return np.concatenate((chromosome1[:randomSplitPoint],chromosome2[randomSplitPoint:])), np.concatenate((chromosome2[:randomSplitPoint],chromosome1[randomSplitPoint:]))\n",
    "\n",
    "\n",
    "def mutate(chromosome):\n",
    "\n",
    "    mutatedChrom = []\n",
    "    for ch in chromosome:\n",
    "        if random.random()<mutationRate:\n",
    "            if ch==1:\n",
    "                mutatedChrom.append(0)\n",
    "            else:\n",
    "                mutatedChrom.append(1)\n",
    "        else:\n",
    "            mutatedChrom.append(ch)\n",
    "    return mutatedChrom\n",
    "    \n",
    "def breed(chrome1, chrome2):\n",
    "    if random.random()<crossOverRate:\n",
    "        newChrome1, newChrome2 = crossover(chrome1, chrome2)\n",
    "    else:\n",
    "        newChrome1 = chrome1\n",
    "        newChrome2 = chrome2\n",
    "        \n",
    "    newChrome1 = mutate(newChrome1)\n",
    "    newChrome2 = mutate(newChrome2)\n",
    "    \n",
    "    return newChrome1, newChrome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankPop(pool, X, y, classifier,fitnessFunction):\n",
    "    scores = []\n",
    "    for chromosome in pool:\n",
    "        classifier = RandomForestClassifier()\n",
    "        chosen_idx = [idx for gene, idx in zip(chromosome, range(X.shape[1])) if gene==1]\n",
    "        if len(chosen_idx)==0:\n",
    "            continue\n",
    "        chosenX = X.iloc[:, chosen_idx]\n",
    "        #performing leave-one out validation for instances less than 100\n",
    "        #and 10 fold validation for others\n",
    "        npoints = X.shape[0]\n",
    "   \n",
    "        if npoints <= 100:\n",
    "            kf = KFold(n_splits = npoints)\n",
    "        else:\n",
    "            kf = KFold(n_splits = 10)\n",
    "        \n",
    "        kf.get_n_splits(X)\n",
    "        classifier.fit(chosenX, y)\n",
    "        train_X = []\n",
    "        train_Y  = []\n",
    "        prediction   = []\n",
    "        predict_prob = []\n",
    "        chosenX = np.array(chosenX)\n",
    "        Y = np.array(y)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            classifier = RandomForestClassifier()\n",
    "            for i in train_index:\n",
    "                train_X.append(chosenX[i])\n",
    "                train_Y.append(Y[i])\n",
    "\n",
    "            classifier.fit(train_X, train_Y)\n",
    "            for j in test_index:\n",
    "                prediction.append(classifier.predict([chosenX[j]])[0])\n",
    "                predict_prob.append(classifier.predict_proba([chosenX[j]])[0][1])\n",
    "            train_X  = []\n",
    "            train_Y  = []\n",
    "        \n",
    "   \n",
    "        if(fitnessFunction == 'f-measure'):\n",
    "            scores.append(f1_score(y_true=y,y_pred=prediction))\n",
    "        elif(fitnessFunction == 'g-mean'):\n",
    "            gScore = math.sqrt(precision_score(y_true = y, y_pred=prediction)*recall_score(y_true = y, y_pred =prediction ))\n",
    "            scores.append(gScore)\n",
    "        elif(fitnessFunction == 'accuracy'):\n",
    "            scores.append(accuracy_score(y_true = y, y_pred = prediction))\n",
    "        \n",
    "    fitness = [x/sum(scores) for x in scores]\n",
    "    pairedPop = zip(pool, fitness)\n",
    "    rankedPop = sorted(pairedPop, key=itemgetter(-1), reverse = True)\n",
    "    \n",
    "    return rankedPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteratePop(rankedPop):\n",
    "    fitness = [item[-1] for item in rankedPop]\n",
    "    rankedPool = [item[0] for item in rankedPop]\n",
    "   \n",
    "    new_pool = []\n",
    "    new_pool.extend(rankedPool[:int(poolSize/15)])\n",
    "    \n",
    "    while(len(new_pool)<poolSize):\n",
    "        ch1, ch2 = selectFittest(fitness, rankedPool)\n",
    "        ch1, ch2 = breed(ch1, ch2)\n",
    "        \n",
    "        new_pool.append(ch1)\n",
    "        new_pool.append(ch2)\n",
    "    \n",
    "    return new_pool[:poolSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgoFit(datafile,measure):\n",
    "    datafile = pd.read_csv(datafile, dtype={'buggy':np.bool})\n",
    "    X     = datafile.iloc[ : , :-1]\n",
    "    y = datafile['buggy']\n",
    "\n",
    "    pool = np.random.randint(0, 2, (poolSize, X.shape[1]))  \n",
    "    for iteration in range(iterations):\n",
    "#         print iteration\n",
    "        classifier = RandomForestClassifier()\n",
    "        rankedPop = rankPop(pool, X, y, classifier,measure)\n",
    "#         print rankedPop\n",
    "        pool = []\n",
    "        pool = iteratePop(rankedPop)\n",
    "        \n",
    "    best_chromosome = rankPop(pool, X, y, classifier, measure)[0][0]\n",
    "    return best_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7f8a71b1dc21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfileName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneticAlgoFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneticAlgoFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f-measure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneticAlgoFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'g-mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-7203442e972f>\u001b[0m in \u001b[0;36mgeneticAlgoFit\u001b[1;34m(datafile, measure)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#         print iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mrankedPop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrankPop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#         print rankedPop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b5e6bc615202>\u001b[0m in \u001b[0;36mrankPop\u001b[1;34m(pool, X, y, classifier, fitnessFunction)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mtrain_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchosenX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 327\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory = 'dataset/dataset/'\n",
    "for fileName in os.listdir(directory):\n",
    "    print(fileName)\n",
    "    print(geneticAlgoFit(directory+fileName,'accuracy'))\n",
    "    print(geneticAlgoFit(directory+fileName,'f-measure'))\n",
    "    print(geneticAlgoFit(directory+fileName,'g-mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeaturesInEachSoftware = np.array([\n",
    "    [[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1]],\n",
    "    \n",
    "    [[1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1],\n",
    "    [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]],\n",
    "    \n",
    "    [[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]],\n",
    "    \n",
    "    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1]],\n",
    "    \n",
    "    [[0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]],\n",
    "    \n",
    "    [[0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]],\n",
    "    \n",
    "    [[1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1]],\n",
    "    \n",
    "    [[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]],\n",
    "    \n",
    "    [[0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0]]\n",
    "])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n",
      "e-learning.csv\n",
      "intercafe.csv\n",
      "ivy-2.0.csv\n",
      "jedit-4.3.csv\n",
      "kalkulator.csv\n",
      "log4j-1.2.csv\n",
      "lucene-2.4.csv\n",
      "poi-2.5.csv\n",
      "prop-6.csv\n",
      "redaktor.csv\n",
      "serapion.csv\n",
      "sklebagd.csv\n",
      "synapse-1.2.csv\n",
      "systemdata.csv\n",
      "szybkafucha.csv\n",
      "termoproject.csv\n",
      "tomcat.csv\n",
      "velocity-1.6.csv\n",
      "workflow.csv\n",
      "wspomaganiepi.csv\n",
      "xalan-2.7.csv\n",
      "xerces-1.4.csv\n",
      "zuzel.csv\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "directory = 'dataset/dataset/'\n",
    "for fileName in os.listdir(directory):\n",
    "    print fileName\n",
    "    data = pd.read_csv(directory+fileName)\n",
    "    X  = data.iloc[ : , :-1]\n",
    "    Y = data.iloc[:,-1]\n",
    "    accuracyFeature = selectedFeaturesInEachSoftware[index][0]\n",
    "    fMeasureFeature = selectedFeaturesInEachSoftware[index][1]\n",
    "    gMeanFeature = selectedFeaturesInEachSoftware[index][2]\n",
    "   \n",
    "    chosen_idx_accuracy = [idx for gene, idx in zip(accuracyFeature, range(X.shape[1])) if gene==1]\n",
    "    chosen_idx_fMeasure = [idx for gene, idx in zip(fMeasureFeature, range(X.shape[1])) if gene==1]\n",
    "    chosen_idx_gMean = [idx for gene, idx in zip(gMeanFeature, range(X.shape[1])) if gene==1]\n",
    "    \n",
    "    data['Accuracy_Pred'],data['Accuracy_Pred_Prob'] = getPredictions(X.iloc[:,chosen_idx_accuracy],Y)\n",
    "    data['FMeasure_Pred'],data['FMeasure_Pred_Prob'] = getPredictions(X.iloc[:,chosen_idx_fMeasure],Y)\n",
    "    data['GMean_Pred'],data['GMean_Pred_Prob'] = getPredictions(X.iloc[:,chosen_idx_gMean],Y)\n",
    "    data.to_csv('dataset/annotated/'+fileName,index=False)    \n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(X,Y):\n",
    "    \n",
    "    base_learner1 = LogisticRegression(random_state=1)\n",
    "    base_learner2 = DecisionTreeClassifier()\n",
    "    base_learner3 = GaussianNB()\n",
    "\n",
    "    classifier = VotingClassifier(estimators=[\n",
    "                                 ('logregression', base_learner1), \n",
    "                                 ('dtree', base_learner2), \n",
    "                                 ('gnb', base_learner3)], \n",
    "                                  voting='soft')\n",
    "    \n",
    "    npoints = X.shape[0]\n",
    "   \n",
    "    if npoints <= 100:\n",
    "        kf = KFold(n_splits = npoints)\n",
    "    else:\n",
    "        kf = KFold(n_splits = 10)\n",
    "        \n",
    "    kf.get_n_splits(X)\n",
    "    train_X = []\n",
    "    train_Y  = []\n",
    "    prediction   = []\n",
    "    predict_prob = []\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        classifier = RandomForestClassifier()\n",
    "        for i in train_index:\n",
    "            train_X.append(X[i])\n",
    "            train_Y.append(Y[i])\n",
    "\n",
    "        classifier.fit(train_X, train_Y)\n",
    "        for j in test_index:\n",
    "            prediction.append(classifier.predict([X[j]])[0])\n",
    "            predict_prob.append(classifier.predict_proba([X[j]])[0][1])\n",
    "        train_X  = []\n",
    "        train_Y  = []\n",
    "\n",
    "    return prediction,predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSelectedFitnessFunction():\n",
    "    i=1\n",
    "    for fileName in os.listdir('dataset/annotated'):\n",
    "        selectedFitnessFunction = [] \n",
    "        data = pd.read_csv('dataset/annotated/'+fileName)\n",
    "        auc_acc = roc_auc_score(y_true=data['buggy'],y_score=data['Accuracy_Pred'])\n",
    "        auc_fMeas = roc_auc_score(y_true=data['buggy'],y_score=data['FMeasure_Pred'])\n",
    "        auc_gMean = roc_auc_score(y_true=data['buggy'],y_score=data['GMean_Pred'])\n",
    "        \n",
    "        print (auc_acc,auc_fMeas,auc_gMean)\n",
    "        \n",
    "        if auc_acc>auc_fMeas and auc_acc>auc_gMean:\n",
    "            highest = 'Accuracy'\n",
    "        elif auc_fMeas>auc_gMean and auc_fMeas>auc_acc:\n",
    "            highest = 'FMeasure'\n",
    "        else:\n",
    "            highest = 'GMean'\n",
    "        \n",
    "        arr1 = np.array(data['Accuracy_Pred'])\n",
    "        arr2 = np.array(data['FMeasure_Pred'])\n",
    "        arr3 = np.array(data['GMean_Pred'])\n",
    "        buggy = np.array(data['buggy'])\n",
    "        \n",
    "        for i in range(len(arr1)):\n",
    "            flag = False\n",
    "            if arr1[i]==buggy[i] and arr2[i] != buggy[i] and arr3[i] != buggy[i]:\n",
    "                selectedFitnessFunction.append('Accuracy')\n",
    "                flag = True\n",
    "            elif arr1[i]!=buggy[i] and arr2[i] == buggy[i] and arr3[i] == buggy[i]:\n",
    "                selectedFitnessFunction.append('FMeasure')\n",
    "                flag = True\n",
    "            elif arr1[i]!=buggy[i] and arr2[i] != buggy[i] and arr3[i] == buggy[i]:\n",
    "                selectedFitnessFunction.append('GMean')\n",
    "                flag = True\n",
    "                \n",
    "            if flag == False:\n",
    "                selectedFitnessFunction.append(highest)\n",
    "            \n",
    "        data['Function to be selected'] = selectedFitnessFunction\n",
    "#         print data.head()\n",
    "        data.to_csv('dataset/annotated/'+fileName,index=False)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5528457789096086, 0.562755004244366, 0.5547762808401105)\n",
      "(0.4830508474576271, 0.4915254237288136, 0.6915254237288135)\n",
      "(0.625, 0.625, 0.625)\n",
      "(0.7214743589743591, 0.7229166666666667, 0.719551282051282)\n",
      "(0.4979209979209979, 0.5433755433755433, 0.5454545454545454)\n",
      "(0.8333333333333333, 0.6964285714285715, 0.8273809523809523)\n",
      "(0.65625, 0.6197089947089947, 0.5831679894179894)\n",
      "(0.7149868756966669, 0.6844234295782246, 0.724659307468268)\n",
      "(0.8515569813986343, 0.8614463150459148, 0.860578055097716)\n",
      "(0.6287878787878788, 0.6405723905723905, 0.6195286195286194)\n",
      "(0.745836440467313, 0.730673626646781, 0.7206065125528213)\n",
      "(0.6944444444444444, 0.6805555555555555, 0.5833333333333334)\n",
      "(0.5625, 0.7916666666666666, 0.6666666666666667)\n",
      "(0.8247606019151847, 0.8191176470588234, 0.7866963064295486)\n",
      "(0.5932539682539683, 0.5376984126984127, 0.5376984126984127)\n",
      "(0.6753246753246754, 0.5584415584415584, 0.6038961038961039)\n",
      "(0.7771883289124668, 0.7984084880636604, 0.8328912466843501)\n",
      "(0.5423449789646974, 0.5534113773550393, 0.5326504481434059)\n",
      "(0.5836729495669893, 0.6386907794192563, 0.6932840889794532)\n",
      "(0.6434210526315791, 0.6407894736842105, 0.6157894736842106)\n",
      "(0.9166666666666665, 0.9166666666666665, 0.7916666666666666)\n",
      "(0.8630795707633124, 0.8181818181818181, 0.8625227778902612)\n",
      "(0.8945777198539104, 0.8877127312955583, 0.8887356600542531)\n",
      "(0.6899038461538463, 0.8221153846153846, 0.7524038461538461)\n"
     ]
    }
   ],
   "source": [
    "getSelectedFitnessFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svctrain():\n",
    "    directory = 'dataset/dataset/'\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    DSF_directory = 'dataset/DSF/'\n",
    "    for projectName in os.listdir(directory):\n",
    "        print(projectName)\n",
    "        projectData = pd.read_csv(directory + projectName)\n",
    "        annotatedData = pd.read_csv(annotated_directory + projectName)\n",
    "        \n",
    "        #X contains software metrics and Y best ensemble selected\n",
    "        X = np.array(projectData.iloc[ : , :-1])\n",
    "        Y = np.array(annotatedData.iloc[ : , -1])\n",
    "        \n",
    "        npoints = X.shape[0]\n",
    "        \n",
    "        if npoints <= 100:\n",
    "            kf = KFold(n_splits = npoints)\n",
    "        else:\n",
    "            kf = KFold(n_splits = 10)\n",
    "        \n",
    "        kf.get_n_splits(X)\n",
    "        train_X = []\n",
    "        train_Y = []\n",
    "        \n",
    "        predictedEnsemble = []\n",
    "        predict_prob      = []\n",
    "        final_prediction  = []  # this stores the prediction(bugginess) of the best ensemble predicted by SVC\n",
    "        \n",
    "        prediction_constant = '_Pred'\n",
    "        probab_constant = '_Pred_Prob'\n",
    "        \n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            classifier = SVC(probability = True)\n",
    "            \n",
    "            for i in train_index:\n",
    "                train_X.append(X[i])\n",
    "                train_Y.append(Y[i])\n",
    "            \n",
    "            unique_labels = np.unique(train_Y)\n",
    "            if unique_labels.size == 1:\n",
    "                for j in test_index:\n",
    "                    predictedEnsemble.append(unique_labels[0])\n",
    "                    predict_prob.append(annotatedData.loc[j, unique_labels[0] + probab_constant])\n",
    "                    final_prediction.append(annotatedData.loc[j, unique_labels[0] + prediction_constant])\n",
    "           \n",
    "            else:\n",
    "                classifier.fit(train_X, train_Y)\n",
    "                \n",
    "                for j in test_index:\n",
    "                    predictedBestEnsemble = classifier.predict([X[j]])[0]\n",
    "                    predictedEnsemble.append(predictedBestEnsemble)\n",
    "                    final_prediction.append(annotatedData.loc[j, predictedBestEnsemble + prediction_constant])\n",
    "                    \n",
    "            # total probability of available classifiers, i.e the classifiers reported in unique_labels predicting true\n",
    "                    predict_proba_true = 0\n",
    "                    \n",
    "            # probability of classifiers being predicted\n",
    "                    predict_proba_classifiers = classifier.predict_proba([X[j]])[0]\n",
    "                    k = 0\n",
    "            # class probabilities are always reported in a sorted by name fashion, i.e AdaBoost, RandomForest, Voting \n",
    "            # np.unique also reports labels in a sorted by name fashion\n",
    "                    for classifierName in unique_labels:\n",
    "                        predict_proba_true +=  predict_proba_classifiers[k] * annotatedData.loc[j, classifierName + probab_constant]\n",
    "                        k += 1\n",
    "                    predict_prob.append(predict_proba_true)\n",
    "                    \n",
    "        annotatedData['PredictedTechnique'] = predictedEnsemble\n",
    "        annotatedData['DSF_Prediction'] = final_prediction\n",
    "        annotatedData['DSF_Pred_Prob'] = predict_prob\n",
    "        annotatedData.to_csv(DSF_directory + projectName, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-1.6.csv\n",
      "e-learning.csv\n",
      "intercafe.csv\n",
      "ivy-2.0.csv\n",
      "jedit-4.3.csv\n",
      "kalkulator.csv\n",
      "log4j-1.2.csv\n",
      "lucene-2.4.csv\n",
      "poi-2.5.csv\n",
      "prop-6.csv\n",
      "redaktor.csv\n",
      "serapion.csv\n",
      "sklebagd.csv\n",
      "synapse-1.2.csv\n",
      "systemdata.csv\n",
      "szybkafucha.csv\n",
      "termoproject.csv\n",
      "tomcat.csv\n",
      "velocity-1.6.csv\n",
      "workflow.csv\n",
      "wspomaganiepi.csv\n",
      "xalan-2.7.csv\n",
      "xerces-1.4.csv\n",
      "zuzel.csv\n"
     ]
    }
   ],
   "source": [
    "svctrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasuresDSF():\n",
    "    DSEdirectory = 'dataset/DSF/'\n",
    "    projectMetrics = []\n",
    "    index = 0\n",
    "    projectMetrics = pd.DataFrame(projectMetrics,\n",
    "                                    columns = ['Project','Precision', 'Recall', 'Auc_Score', 'Accuracy', 'Fmeasure', 'GMean'])\n",
    "    for projectName in os.listdir(DSEdirectory):\n",
    "        project = pd.read_csv(DSEdirectory + projectName)\n",
    "        projectData = project.as_matrix(columns=[\n",
    "                                         'DSF_Prediction',\n",
    "                                         'DSF_Pred_Prob',\n",
    "                                         'buggy'])\n",
    "      \n",
    "        row = []\n",
    "        row.append(projectName)\n",
    "        row.extend(computePerformanceMeasures(project['DSF_Prediction'], \n",
    "                                                         project['buggy'], \n",
    "                                                         project['DSF_Pred_Prob']))\n",
    "        projectMetrics.loc[index] = row\n",
    "        index = index + 1\n",
    "  \n",
    "    print(projectMetrics)\n",
    "    projectMetrics.to_csv('dataset/' + 'results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Project  Precision    Recall  Auc_Score  Accuracy  Fmeasure  \\\n",
      "0       camel-1.6.csv   0.678161  0.313830   0.732201  0.837306  0.429091   \n",
      "1      e-learning.csv   0.666667  0.400000   0.738983  0.937500  0.500000   \n",
      "2       intercafe.csv   1.000000  0.250000   0.793478  0.888889  0.400000   \n",
      "3         ivy-2.0.csv   0.833333  0.625000   0.905489  0.897959  0.714286   \n",
      "4       jedit-4.3.csv   1.000000  0.090909   0.710546  0.979675  0.166667   \n",
      "5      kalkulator.csv   1.000000  0.916667   0.920635  0.969697  0.956522   \n",
      "6       log4j-1.2.csv   0.945000  1.000000   0.674603  0.946341  0.971722   \n",
      "7      lucene-2.4.csv   0.827957  0.758621   0.823739  0.761765  0.791774   \n",
      "8         poi-2.5.csv   0.924107  0.834677   0.937765  0.888889  0.877119   \n",
      "9          prop-6.csv   0.462963  0.378788   0.717401  0.893939  0.416667   \n",
      "10       redaktor.csv   0.777778  0.518519   0.782128  0.903409  0.622222   \n",
      "11       serapion.csv   1.000000  0.444444   0.833333  0.888889  0.615385   \n",
      "12       sklebagd.csv   0.916667  0.916667   0.802083  0.900000  0.916667   \n",
      "13    synapse-1.2.csv   0.885542  0.854651   0.902035  0.871345  0.869822   \n",
      "14     systemdata.csv   0.750000  0.333333   0.688492  0.892308  0.461538   \n",
      "15    szybkafucha.csv   0.769231  0.714286   0.707792  0.720000  0.740741   \n",
      "16   termoproject.csv   0.875000  0.807692   0.900531  0.854545  0.840000   \n",
      "17         tomcat.csv   0.586207  0.220779   0.765111  0.916084  0.320755   \n",
      "18   velocity-1.6.csv   0.746032  0.602564   0.805994  0.794760  0.666667   \n",
      "19       workflow.csv   0.777778  0.700000   0.810526  0.743590  0.736842   \n",
      "20  wspomaganiepi.csv   0.900000  0.750000   0.916667  0.833333  0.818182   \n",
      "21      xalan-2.7.csv   0.994463  1.000000   0.945839  0.994565  0.997224   \n",
      "22     xerces-1.4.csv   0.940789  0.981693   0.949293  0.940476  0.960806   \n",
      "23          zuzel.csv   0.833333  0.769231   0.788462  0.827586  0.800000   \n",
      "\n",
      "       GMean  \n",
      "0   0.461332  \n",
      "1   0.516398  \n",
      "2   0.500000  \n",
      "3   0.721688  \n",
      "4   0.301511  \n",
      "5   0.957427  \n",
      "6   0.972111  \n",
      "7   0.792531  \n",
      "8   0.878255  \n",
      "9   0.418766  \n",
      "10  0.635053  \n",
      "11  0.666667  \n",
      "12  0.916667  \n",
      "13  0.869960  \n",
      "14  0.500000  \n",
      "15  0.741249  \n",
      "16  0.840673  \n",
      "17  0.359753  \n",
      "18  0.670471  \n",
      "19  0.737865  \n",
      "20  0.821584  \n",
      "21  0.997228  \n",
      "22  0.961024  \n",
      "23  0.800641  \n"
     ]
    }
   ],
   "source": [
    "computePerformanceMeasuresDSF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasures(predictions, labels, prediction_probability):\n",
    "    \n",
    "    precision = precision_score(y_true = labels, y_pred = predictions)\n",
    "    recall    = recall_score(y_true = labels, y_pred = predictions)\n",
    "    roc_score = roc_auc_score(labels, prediction_probability)\n",
    "    accuracy  = accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    f_measure = 2*(precision * recall)/float(precision + recall) \n",
    "    g_mean = math.sqrt(precision * recall)\n",
    "    \n",
    "    metrics = [precision, recall, roc_score, accuracy, f_measure, g_mean]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasuresForTechniques():\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    resultsFile = open('dataset/performanceMeasures.csv','w+')\n",
    "    for projectName in os.listdir(annotated_directory):\n",
    "        project = pd.read_csv(annotated_directory+projectName)\n",
    "        for techniques in ['Accuracy','FMeasure','GMean']:\n",
    "            prediction = project[techniques+'_Pred']\n",
    "            labels     = project['buggy']\n",
    "            prediction_probability = project[techniques+'_Pred_Prob']\n",
    "            measures = (','.join(str(x) for x in computePerformanceMeasures(prediction,labels,prediction_probability))+'\\n')\n",
    "            resultsFile.write(str(projectName)+','+techniques+','+measures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "computePerformanceMeasuresForTechniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
